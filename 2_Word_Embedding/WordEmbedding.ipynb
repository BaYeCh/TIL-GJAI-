{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39b2cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'C:/pytest/word2vec/'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "248e80c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a42ce8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "025d6649",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wiki_test.txt','r',encoding = 'utf-8') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d20fd599",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf832ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\광주인공지능사관학교\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rhinoMorph\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0bf5d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath:  C:\\Anaconda3\\lib\\site-packages\n",
      "classpath:  C:\\Anaconda3\\lib\\site-packages\\rhinoMorph/lib/rhino.jar\n",
      "RHINO started!\n"
     ]
    }
   ],
   "source": [
    "sent_data = sent_tokenize(data)\n",
    "rn = rhinoMorph.startRhino()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78ea9015",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "11977\n",
      "['<doc id=\"5\" url=\"https://ko.wikipedia.org/wiki?curid=5\" title=\"지미 카터\">\\n지미 카터\\n\\n제임스 얼 \"지미\" 카터 주니어(, 1924년 10월 1일 ~ )는 민주당 출신 미국 39번째 대통령 (1977년 ~ 1981년)이다.', '지미 카터는 조지아주 섬터 카운티 플레인스 마을에서 태어났다.', '조지아 공과대학교를 졸업하였다.', '그 후 해군에 들어가 전함·원자력·잠수함의 승무원으로 일하였다.', '1953년 미국 해군 대위로 예편하였고 이후 땅콩·면화 등을 가꿔 많은 돈을 벌었다.', '그의 별명이 \"땅콩 농부\" (Peanut Farmer)로 알려졌다.', '1962년 조지아 주 상원 의원 선거에서 낙선하나 그 선거가 부정선거 였음을 입증하게 되어 당선되고, 1966년 조지아 주 지사 선거에 낙선하지만 1970년 조지아 주 지사를 역임했다.', '대통령이 되기 전 조지아주 상원의원을 두번 연임했으며, 1971년부터 1975년까지 조지아 지사로 근무했다.', '조지아 주지사로 지내면서, 미국에 사는 흑인 등용법을 내세웠다.', '1976년 대통령 선거에 민주당 후보로 출마하여 도덕주의 정책으로 내세워, 포드를 누르고 당선되었다.', '카터 대통령은 에너지 개발을 촉구했으나 공화당의 반대로 무산되었다.', '카터는 이집트와 이스라엘을 조정하여, 캠프 데이비드에서 안와르 사다트 대통령과 메나헴 베긴 수상과 함께 중동 평화를 위한 캠프데이비드 협정을 체결했다.', '그러나 이것은 공화당과 미국의 유대인 단체의 반발을 일으켰다.', '1979년 백악관에서 양국 간의 평화조약으로 이끌어졌다.', '또한 소련과 제2차 전략 무기 제한 협상에 조인했다.', '카터는 1970년대 후반 당시 대한민국 등 인권 후진국의 국민들의 인권을 지키기 위해 노력했으며, 취임 이후 계속해서 도덕정치를 내세웠다.', '<!DOCTYPE tei.2  SYSTEM \"c:굎gml괺td굏ei2.dtd\" [\\n        <!ENTITY % TEI.corpus \"INCLUDE\">\\n        <!ENTITY % TEI.extensions.ent SYSTEM \"sejong1.ent\">\\n        <!ENTITY % TEI.extensions.dtd SYSTEM \"sejong1.dtd\">\\n    ]>\\n<tei.2>\\n<teiHeader>\\n<fileDesc>\\n   <titleStmt>\\n      <title>조선일보 90년 인터뷰기사</title>\\n      <author>박태준외, 기자들</author>\\n      <sponsor>대한민국 문화관광부</sponsor>\\n      <respStmt><resp>전자/표준화</resp>\\n            <name>고려대학교 민족문화연구원</name>\\n      </respStmt>\\n   </titleStmt>\\n   <extent> 55692어절</extent>\\n   <publicationStmt>\\n      <distributor>국립국어연구원</distributor>\\n      <idno>2ba90a03.hwp</idno>\\n      <availability><p>배포 불가</p></availability>\\n   </publicationStmt>\\n   <sourceDesc><p>원전 : 조선일보 인터뷰기사를 CTS파일에서 전자파일화.</p></sourceDesc>\\n</fileDesc>\\n<encodingDesc>\\n   <projectDesc><p>21세기 세종계획 2차년도 말뭉치 구축</p></projectDesc>\\n\\n   <samplingDecl><p>CTS파일을 전자파일화.</p></samplingDecl>\\n   <editorialDecl>\\n      <normalization><p>21세기 세종계획 말뭉치 문헌 입력 지침에 따름</p></normalization>\\n   </editorialDecl>\\n</encodingDesc>\\n<profileDesc>\\n   <creation><date>1990</date></creation>\\n   <samplingDecl><p>CTS파일을 전자파일화.</p></samplingDecl>\\n   <langUsage>\\n         <language id=KO usage=99>한국어, 표준어</language>\\n   </langUsage>\\n   <particDesc>\\n         <person id=P1 sex=?', 'age=?>박태준외</person>\\n         <person id=P2 sex=?', 'age=?>기자들</person>\\n   </particDesc>\\n   <settingDesc>\\n         <setting who=\\'P1 P2\\'>\\n         <p>1990년 조선일보 인터뷰기사를 전자파일로 입수</p>\\n         </setting>\\n   </settingDesc>\\n   <textClass>\\n         <catRef scheme=\\'SJ21\\' target=\\'M2104\\'></catRef>  \\n   </textClass>\\n</profileDesc>\\n<revisionDesc>\\n  <respStmt>\\n        <resp>프로젝트책임자</resp><name>김흥규</name>\\n  </respStmt>\\n   <change><date>1994</date><respStmt><name>한국언론연구원</name></respStmt>\\n        <item>CTS파일을 전자파일화</item>\\n   </change>\\n   <change><date>1996/08</date><respStmt><name>최민우</name></respStmt>\\n        <item>헤더붙임</item>\\n   </change>\\n  <change><date>1999/11</date><respStmt><name>박병선</name></respStmt>\\n        <item>파일 포맷 변환, 교정, 세종 21 계획 헤더 붙임, 마킹, 검토</item>\\n   </change>\\n</revisionDesc>\\n</teiHeader>\\n\\n<text>\\n<group>\\n<text><body>\\n<source>\\n  <date>1990/01/06</date>\\n  <page>02</page>\\n</source>\\n<head>\"정치 신뢰회복 최선 다하겠다\" / 박태준 민정대표 일문일답</head>\\n<head>\"당내 융화-결속엔 별 문제 없어 / 민주화 촉진-경제난 극복에 맞춰 당운영\"</head>\\n<p>민정당의 신임 박태준대표위원은 \"기왕에 정치일선에 나선이상 신명을 바쳐 저하된 정치의 신뢰를 회복하는 데 최선을 다하겠다\"고 첫 소감을 말했다.</p>\\n<p>5일 오후 노태우대통령으로부터 대표위원 임명통보를 받은 뒤 오후 4 시쯤 민정당사에 도착, 곧바로 가진 기자회견에서 그는 밝은 표정으로 질문에 응했으나 정계개편등 중요 현안에 대해서는 \"앞으로 공부를 더해 답하겠다\"는 말로 답변을 대신했다.</p>\\n<p>- 어려운 시기에 대표위원을 맡았는데….</p>\\n<p>\"해외여행에서 돌아오자마자 대임을 맡게 돼, 아직까지 생각을 정리해 본 적은 없습니다.', '그러나 평소 정치의 신뢰가 대단히 저하됐다고 생각해  왔기 때문에 동료의원들의 협조를 얻어 정치의 신뢰를 회복시키고 국민들이 정치걱정하지 않고 생업에 충실할 수 있도록 최선을 다하겠습니다.']\n"
     ]
    }
   ],
   "source": [
    "print(type(sent_data), len(sent_data), sent_data[:20], sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2457e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('./word2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5982c1f",
   "metadata": {},
   "source": [
    "# Word2Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed7a4ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 11977/11977 [00:27<00:00, 432.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "with open('./word2vec/wiki_test_morphed.txt','w', encoding = 'utf-8') as f:\n",
    "    for data_each in tqdm(sent_data):\n",
    "        morphed_data_each = rhinoMorph.onlyMorph_list(rn, data_each, pos = ['NNP','NNG','VV','VA','XR','IC','MM','MAG','MAJ'],\n",
    "                                                     xrVv = True, eomi = True)\n",
    "        joined_data_each = ' '.join(morphed_data_each)\n",
    "        if joined_data_each:\n",
    "            f.write(joined_data_each + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f1974a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename, encoding = 'utf-8'):\n",
    "    with open(filename, 'r', encoding = encoding) as f:\n",
    "        data = [line.split(' ') for line in f.read().splitlines()]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9235d386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11972\n",
      "<class 'list'>\n",
      "[['URL', '미', '카터', '미', '카터', '제임스', '얼다', '미', '카터', '주니어', '민주당', '출신', '미국', '대통령'], ['미', '카터', '조지아', '섬터', '카운티', '마을', '태어나다'], ['조지아', '공과대학', '교', '졸업하다']]\n"
     ]
    }
   ],
   "source": [
    "data = read_data('./word2vec/wiki_test_morphed.txt','utf-8')\n",
    "print(len(data), type(data), data[:3], sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6cde142",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences= data, vector_size= embedding_dim, window= 10, min_count= 5, workers= 4 , sg= 1)\n",
    "model.save('embedding200_window10_mincnt5_skipgram.model')\n",
    "# embedding200_window10_mincnt5_skipgram.model.wv.vectors.npy\n",
    "# 단어와 임베딩 값을 가지고 있는 파일\n",
    "# embedding200_window10_mincnt5_skipgram.model.syn1neg.npy\n",
    "# 임베딩 값을 계산하기 위해 사용된 신경망 네트워크와 가중치 보유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dc70bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10643/10643 [00:02<00:00, 4046.61it/s]\n"
     ]
    }
   ],
   "source": [
    "words = list(model.wv.index_to_key)\n",
    "with open('embedding200_window10_mincnt5_skipgram.txt','w') as f:\n",
    "    for word in tqdm(words):\n",
    "        data = model.wv[word].tolist() # 200개의 가중치를 리스트로\n",
    "        data.insert(0, word) # 데이터의 0번 위치에 해당 단어를 끼워 넣음\n",
    "                             # 알아보기 쉽게 함\n",
    "        for item in data: # 단어 이름부터 시작하여 각 벡터 값을 저장\n",
    "            f.write('%s ' % item)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b743a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 유사단어 출력 ---\n",
      "[('행복하다', 0.9828894138336182), ('맴돌다', 0.9787048697471619), ('고뇌', 0.9784281849861145), ('감동', 0.9782537817955017), ('따뜻하다', 0.9779002666473389), ('소망', 0.97676682472229), ('두텁다', 0.9756407737731934), ('선비', 0.9752475023269653), ('애꾸눈', 0.9741258025169373), ('설레다', 0.9733781814575195)]\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load('embedding200_window10_mincnt5_skipgram.model')\n",
    "\n",
    "print('--- 유사단어 출력 ---')\n",
    "similarWords = model.wv.most_similar(positive= ['행복','웃음','밝다','기쁨'], topn=10)\n",
    "print(similarWords) # 확률값, 정도값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c87adbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['행복하다', '맴돌다', '고뇌', '감동', '따뜻하다', '소망', '두텁다', '선비', '애꾸눈', '설레다']\n"
     ]
    }
   ],
   "source": [
    "word = []\n",
    "for similarWord in similarWords:\n",
    "    word.append(similarWord[0])\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38bd0197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 두 단어의 유사도 계산 ---\n",
      "한국과 일본 : 0.5648971796035767\n",
      "한국과 미국 : 0.6623880863189697\n",
      "한국과 중국 : 0.705439031124115\n"
     ]
    }
   ],
   "source": [
    "print('--- 두 단어의 유사도 계산 ---\\n한국과 일본 : {}\\n한국과 미국 : {}\\n한국과 중국 : {}'.format(model.wv.similarity('한국','일본'),model.wv.similarity('한국','미국'),model.wv.similarity('한국','중국')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b4d073e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 유사단어 출력 ---\n",
      "[('행복하다', 0.7607556581497192), ('기쁘다', 0.7480962872505188), ('즐겁다', 0.7307630181312561), ('흐뭇하다', 0.7170217037200928), ('즐거움', 0.7020072340965271), ('자약하다', 0.6902682781219482), ('아름답다', 0.676089346408844), ('법열감', 0.6757972836494446), ('유쾌하다', 0.6678250432014465), ('해맑다', 0.6666801571846008)]\n",
      "['행복하다', '기쁘다', '즐겁다', '흐뭇하다', '즐거움', '자약하다', '아름답다', '법열감', '유쾌하다', '해맑다']\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load('embedding_window10_mincnt5_skipgram_big.model')\n",
    "print('--- 유사단어 출력 ---')\n",
    "similarWords = model.wv.most_similar(positive= ['행복','웃음','밝다','기쁨'], topn=10)\n",
    "print(similarWords) # 확률값, 정도값\n",
    "word = []\n",
    "for similarWord in similarWords:\n",
    "    word.append(similarWord[0])\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c481e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 두 단어의 유사도 계산 ---\n",
      "한국과 일본 : 0.7467085123062134\n",
      "한국과 미국 : 0.6853418350219727\n",
      "한국과 중국 : 0.5778185129165649\n"
     ]
    }
   ],
   "source": [
    "print('--- 두 단어의 유사도 계산 ---\\n한국과 일본 : {}\\n한국과 미국 : {}\\n한국과 중국 : {}'.format(model.wv.similarity('한국','일본'),model.wv.similarity('한국','미국'),model.wv.similarity('한국','중국')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb35b10",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d22d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('C:/pytest/fasttext/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c22e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/pytest/fasttext/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49bf07bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11972\n",
      "<class 'list'>\n",
      "[['URL', '미', '카터', '미', '카터', '제임스', '얼다', '미', '카터', '주니어', '민주당', '출신', '미국', '대통령'], ['미', '카터', '조지아', '섬터', '카운티', '마을', '태어나다'], ['조지아', '공과대학', '교', '졸업하다']]\n"
     ]
    }
   ],
   "source": [
    "data = read_data('C:/pytest/word2vec/wiki_test_morphed.txt','utf-8')\n",
    "print(len(data), type(data), data[:3], sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e7a7d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "model = FastText(sentences= data, vector_size= embedding_dim, window= 10, min_count= 2, workers= 4)\n",
    "model.save('embedding200_window10_mincnt2_fasttext.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0186d428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 유사단어 출력 ---\n",
      "[('젊은', 0.9997346997261047), ('키우다', 0.9997287392616272), ('채우다', 0.9997075796127319), ('씌우다', 0.9996822476387024), ('거세다', 0.9996662139892578), ('길이', 0.9996564388275146), ('배우다', 0.999651312828064), ('북돋우다', 0.9996458292007446), ('몰려들다', 0.9996426105499268), ('치켜세우다', 0.9996381998062134)]\n",
      "['젊은', '키우다', '채우다', '씌우다', '거세다', '길이', '배우다', '북돋우다', '몰려들다', '치켜세우다']\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load('embedding200_window10_mincnt2_fasttext.model')\n",
    "print('--- 유사단어 출력 ---')\n",
    "similarWords = model.wv.most_similar(positive= ['행복','웃음','밝다','기쁨'], topn=10)\n",
    "print(similarWords) # 확률값, 정도값\n",
    "word = []\n",
    "for similarWord in similarWords:\n",
    "    word.append(similarWord[0])\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cca6f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 두 단어의 유사도 계산 ---\n",
      "한국과 일본 : 0.9854395389556885\n",
      "한국과 미국 : 0.9394056797027588\n",
      "한국과 중국 : 0.9936444163322449\n"
     ]
    }
   ],
   "source": [
    "print('--- 두 단어의 유사도 계산 ---\\n한국과 일본 : {}\\n한국과 미국 : {}\\n한국과 중국 : {}'.format(model.wv.similarity('한국','일본'),model.wv.similarity('한국','미국'),model.wv.similarity('한국','중국')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff4882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
