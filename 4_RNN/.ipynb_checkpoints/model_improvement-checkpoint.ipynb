{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24be1c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"C:/pytest/\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d305afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f62ec02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_train = pd.read_csv('data1_train.csv',encoding= 'cp949')\n",
    "data1_test = pd.read_csv('data1_test.csv',encoding= 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ed734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_train = pd.read_csv('data2_train.csv',encoding= 'cp949')\n",
    "data2_test = pd.read_csv('data2_test.csv',encoding= 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d71050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_train_X_morphed = data1_train['텍스트']\n",
    "data1_train_y = data1_train['분류1_상위']\n",
    "data1_test_X_morphed = data1_train['텍스트']\n",
    "data1_test_y = data1_train['분류1_상위']\n",
    "\n",
    "data2_train_X_morphed = data2_train['텍스트']\n",
    "data2_train_y = data2_train['분류2_상위']\n",
    "data2_test_X_morphed = data2_train['텍스트']\n",
    "data2_test_y = data2_train['분류2_상위']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ecfbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4afc7212",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "maxlen = 30\n",
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17cbaa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(data1_train_X_morphed)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "tokenizer2 = Tokenizer(num_words= max_words)\n",
    "tokenizer2.fit_on_texts(data2_train_X_morphed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a2c1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5b17d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequencing \n",
    "data1_train_X_sequencing = tokenizer.texts_to_sequences(data1_train_X_morphed)\n",
    "# padding\n",
    "data1_train_X_padding = pad_sequences(data1_train_X_sequencing, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71eaf871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2 sequencing \n",
    "data2_train_X_sequencing = tokenizer2.texts_to_sequences(data2_train_X_morphed)\n",
    "# padding\n",
    "data2_train_X_padding = pad_sequences(data2_train_X_sequencing, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f84b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "e = LabelEncoder()\n",
    "e.fit(data1_train_y)\n",
    "data1_train_y_labeling = e.transform(data1_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "193d9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2\n",
    "e2 = LabelEncoder()\n",
    "e2.fit(data2_train_y)\n",
    "data2_train_y_labeling = e2.transform(data2_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70244e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IT_과학' '경제' '국제' '문화' '미분류' '사회' '스포츠' '정치' '지역'] ['IT_과학' '경제' '국제' '문화' '사회' '스포츠' '정치' '지역']\n"
     ]
    }
   ],
   "source": [
    "print(e.classes_, e2.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dc2efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(sequences, dimension):\n",
    "  results = np.zeros((len(sequences), dimension))\n",
    "  for i, sequence in enumerate(sequences):\n",
    "    results[i, sequence] = 1\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "240ec475",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_train_y_1hot = to_one_hot(data1_train_y_labeling, len(e.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a636276",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_train_y_1hot = to_one_hot(data2_train_y_labeling, len(e2.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9996d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_number = len(e.classes_)\n",
    "class_number2 = len(e2.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0f4448a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 30, 200)           2000000   \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 100)               120400    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                3232      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,123,929\n",
      "Trainable params: 2,123,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers, regularizers\n",
    "# model = Sequential()\n",
    "# model.add(layers.Embedding(input_dim = max_words, output_dim = embedding_dim, input_length = maxlen))\n",
    "# model.add(layers.Bidirectional(layers.LSTM(100,return_sequences = True)))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Bidirectional(layers.LSTM(100)))\n",
    "# model.add(layers.Dense(32, kernel_regularizer = regularizers.L2(0.0001), activation = 'relu'))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Dense(class_number, activation=  'softmax'))\n",
    "# model.summary()\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim = max_words, output_dim = embedding_dim, input_length = maxlen))\n",
    "model.add(layers.LSTM(100))\n",
    "model.add(layers.Dense(32, kernel_regularizer = regularizers.L2(0.0001), activation = 'relu'))\n",
    "model.add(layers.Dense(class_number, activation=  'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fc115dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 30, 200)           2000000   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 30, 200)          240800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 30, 200)           0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 200)              240800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                6432      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,488,296\n",
      "Trainable params: 2,488,296\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(layers.Embedding(input_dim = max_words, output_dim = embedding_dim, input_length = maxlen))\n",
    "model2.add(layers.Bidirectional(layers.LSTM(100,return_sequences = True)))\n",
    "model2.add(layers.Dropout(0.5))\n",
    "model2.add(layers.Bidirectional(layers.LSTM(100)))\n",
    "model2.add(layers.Dense(32,kernel_regularizer = regularizers.L2(0.0001), activation = 'relu'))\n",
    "model2.add(layers.Dropout(0.5))\n",
    "model2.add(layers.Dense(class_number2, activation=  'softmax'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42e10edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor = 'acc', patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a777fba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "149/149 [==============================] - 3s 11ms/step - loss: 1.4736 - acc: 0.4777 - val_loss: 1.2183 - val_acc: 0.5569\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.9025 - acc: 0.6967 - val_loss: 1.0467 - val_acc: 0.6526\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.6116 - acc: 0.8006 - val_loss: 0.9296 - val_acc: 0.6845\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.3960 - acc: 0.8790 - val_loss: 0.9664 - val_acc: 0.7017\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.2525 - acc: 0.9268 - val_loss: 1.1942 - val_acc: 0.6531\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.1633 - acc: 0.9523 - val_loss: 1.2113 - val_acc: 0.7046\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.1003 - acc: 0.9699 - val_loss: 1.4616 - val_acc: 0.6904\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0570 - acc: 0.9844 - val_loss: 1.7447 - val_acc: 0.6806\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0439 - acc: 0.9899 - val_loss: 1.7019 - val_acc: 0.6938\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0298 - acc: 0.9931 - val_loss: 1.8270 - val_acc: 0.6884\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0185 - acc: 0.9941 - val_loss: 2.1652 - val_acc: 0.7056\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0238 - acc: 0.9941 - val_loss: 1.8356 - val_acc: 0.6865\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0149 - acc: 0.9966 - val_loss: 2.0882 - val_acc: 0.6992\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0115 - acc: 0.9979 - val_loss: 2.1666 - val_acc: 0.6963\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0088 - acc: 0.9977 - val_loss: 2.1130 - val_acc: 0.6963\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0063 - acc: 0.9979 - val_loss: 2.0041 - val_acc: 0.6830\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0051 - acc: 0.9987 - val_loss: 1.9915 - val_acc: 0.6938\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0108 - acc: 0.9979 - val_loss: 2.1075 - val_acc: 0.6953\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0052 - acc: 0.9992 - val_loss: 2.1045 - val_acc: 0.6923\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0031 - acc: 0.9994 - val_loss: 2.1985 - val_acc: 0.6938\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0060 - acc: 0.9987 - val_loss: 2.2305 - val_acc: 0.6825\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0040 - acc: 0.9994 - val_loss: 2.2307 - val_acc: 0.6835\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0036 - acc: 0.9994 - val_loss: 2.3700 - val_acc: 0.6865\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss= 'categorical_crossentropy',optimizer= 'rmsprop',metrics = ['acc'])\n",
    "history1 = model.fit(data1_train_X_padding, data1_train_y_1hot,epochs = 100, batch_size =32, validation_split= 0.3,verbose = 1,callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74fc46df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "104/104 [==============================] - 9s 34ms/step - loss: 1.8716 - acc: 0.3069 - val_loss: 1.5669 - val_acc: 0.4560\n",
      "Epoch 2/100\n",
      "104/104 [==============================] - 2s 20ms/step - loss: 1.4227 - acc: 0.5234 - val_loss: 1.4681 - val_acc: 0.5130\n",
      "Epoch 3/100\n",
      "104/104 [==============================] - 2s 20ms/step - loss: 1.0783 - acc: 0.6542 - val_loss: 1.4202 - val_acc: 0.5518\n",
      "Epoch 4/100\n",
      "104/104 [==============================] - 2s 20ms/step - loss: 0.8131 - acc: 0.7551 - val_loss: 1.4810 - val_acc: 0.5736\n",
      "Epoch 5/100\n",
      "104/104 [==============================] - 2s 20ms/step - loss: 0.5942 - acc: 0.8275 - val_loss: 1.5105 - val_acc: 0.5913\n",
      "Epoch 6/100\n",
      "104/104 [==============================] - 2s 20ms/step - loss: 0.4257 - acc: 0.8861 - val_loss: 1.7998 - val_acc: 0.5842\n",
      "Epoch 7/100\n",
      "104/104 [==============================] - 2s 20ms/step - loss: 0.3228 - acc: 0.9145 - val_loss: 2.1593 - val_acc: 0.5588\n",
      "Epoch 8/100\n",
      "104/104 [==============================] - 2s 21ms/step - loss: 0.2130 - acc: 0.9408 - val_loss: 2.3551 - val_acc: 0.5715\n",
      "Epoch 9/100\n",
      "104/104 [==============================] - 2s 20ms/step - loss: 0.1718 - acc: 0.9583 - val_loss: 2.8639 - val_acc: 0.5722\n",
      "Epoch 10/100\n",
      "104/104 [==============================] - 2s 20ms/step - loss: 0.1374 - acc: 0.9698 - val_loss: 3.1995 - val_acc: 0.5899\n",
      "Epoch 11/100\n",
      "104/104 [==============================] - 2s 20ms/step - loss: 0.1122 - acc: 0.9770 - val_loss: 3.4435 - val_acc: 0.5842\n",
      "Epoch 12/100\n",
      "104/104 [==============================] - 2s 21ms/step - loss: 0.0927 - acc: 0.9770 - val_loss: 3.9450 - val_acc: 0.5772\n",
      "Epoch 13/100\n",
      "104/104 [==============================] - 2s 20ms/step - loss: 0.0650 - acc: 0.9834 - val_loss: 4.3881 - val_acc: 0.5899\n",
      "Epoch 14/100\n",
      "104/104 [==============================] - 2s 21ms/step - loss: 0.0629 - acc: 0.9822 - val_loss: 4.5619 - val_acc: 0.5927\n",
      "Epoch 15/100\n",
      "104/104 [==============================] - 2s 21ms/step - loss: 0.0568 - acc: 0.9864 - val_loss: 5.0543 - val_acc: 0.5856\n",
      "Epoch 16/100\n",
      "104/104 [==============================] - 2s 21ms/step - loss: 0.0502 - acc: 0.9867 - val_loss: 4.8134 - val_acc: 0.5884\n",
      "Epoch 17/100\n",
      "104/104 [==============================] - 2s 21ms/step - loss: 0.0570 - acc: 0.9870 - val_loss: 5.1171 - val_acc: 0.5856\n",
      "Epoch 18/100\n",
      "104/104 [==============================] - 2s 21ms/step - loss: 0.0535 - acc: 0.9879 - val_loss: 5.5687 - val_acc: 0.5906\n",
      "Epoch 19/100\n",
      "104/104 [==============================] - 2s 21ms/step - loss: 0.0581 - acc: 0.9888 - val_loss: 5.6908 - val_acc: 0.5934\n",
      "Epoch 20/100\n",
      "104/104 [==============================] - 2s 20ms/step - loss: 0.0424 - acc: 0.9888 - val_loss: 5.9528 - val_acc: 0.5758\n",
      "Epoch 21/100\n",
      "104/104 [==============================] - 2s 20ms/step - loss: 0.0464 - acc: 0.9918 - val_loss: 5.8554 - val_acc: 0.5814\n",
      "Epoch 22/100\n",
      "104/104 [==============================] - 2s 20ms/step - loss: 0.0383 - acc: 0.9909 - val_loss: 5.9617 - val_acc: 0.6025\n",
      "Epoch 23/100\n",
      "104/104 [==============================] - 2s 21ms/step - loss: 0.0365 - acc: 0.9915 - val_loss: 5.9627 - val_acc: 0.6117\n",
      "Epoch 24/100\n",
      "104/104 [==============================] - 2s 21ms/step - loss: 0.0393 - acc: 0.9891 - val_loss: 6.6323 - val_acc: 0.5913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1ec44ba08>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss= 'categorical_crossentropy',optimizer= 'rmsprop',metrics = ['acc'])\n",
    "model2.fit(data2_train_X_padding, data2_train_y_1hot,epochs = 100, batch_size =32, validation_split= 0.3,verbose = 1,callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4642865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1\n",
    "# sequencing\n",
    "data1_test_X_sequencing = tokenizer.texts_to_sequences(data1_test_X_morphed)\n",
    "# padding\n",
    "data1_test_X_padding = pad_sequences(data1_test_X_sequencing, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b181e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2\n",
    "# sequencing\n",
    "data2_test_X_sequencing = tokenizer2.texts_to_sequences(data2_test_X_morphed)\n",
    "# padding\n",
    "data2_test_X_padding = pad_sequences(data2_test_X_sequencing, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab7f1254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 test_y\n",
    "data1_test_y_labeling= e.transform(data1_test_y)\n",
    "data1_test_y_1hot = to_one_hot(data1_test_y_labeling, class_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "483c2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2 test_y\n",
    "data2_test_y_labeling= e2.transform(data2_test_y)\n",
    "data2_test_y_1hot = to_one_hot(data2_test_y_labeling, class_number2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34c7ac39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 2s 7ms/step - loss: 1.2021 - acc: 0.9084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2021019458770752, 0.9084216952323914]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data1 분류1\n",
    "model.evaluate(data1_test_X_padding, data1_test_y_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79862ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 7ms/step - loss: 1.9955 - acc: 0.8770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.995505928993225, 0.8769556283950806]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data2 분류2\n",
    "model2.evaluate(data2_test_X_padding, data2_test_y_1hot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
