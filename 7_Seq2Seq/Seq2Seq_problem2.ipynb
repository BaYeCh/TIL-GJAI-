{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad5eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'C:/pytest/data/kor-eng/'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd31ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acaec187",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('kor-eng.txt', names = ['source','target'],sep = '\\t', encoding = 'utf-8')[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b8ddbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ed980a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       \\tI go to the attic every evening to meet Bat.\\n\n",
       "1        \\tSir, I don't understand this sentence here.\\n\n",
       "2      \\tTime flies when you start using the computer.\\n\n",
       "3         \\tI'm going back to Korea today at midnight.\\n\n",
       "4             \\tI go to bathroom as soon as I wake up.\\n\n",
       "                             ...                        \n",
       "995        \\tIf you were mine, I will be really happy.\\n\n",
       "996    \\tWe have lots in common because we are studen...\n",
       "997    \\tI cannot open it because I have no authority...\n",
       "998           \\tI think we are alike in personalities.\\n\n",
       "999    \\tAnd if we have something to talk about, let'...\n",
       "Name: target, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시작 부호와 종료 부호 부착\n",
    "data.target_input = data.target.apply(lambda x: '\\t'+x+'\\n')\n",
    "data.target_target = data.target.apply(lambda x: x+'\\n')\n",
    "data.target_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1c7df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding 에 사용할 문장의 길이\n",
    "# source\n",
    "max_src_len = data.source.apply(lambda x:len(x)).max()\n",
    "# target\n",
    "max_tar_len = data.target.apply(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51c27d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer_source = Tokenizer(num_words= None, filters = '',lower= False)\n",
    "tokenizer_source.fit_on_texts(data.source)\n",
    "word_index_source = tokenizer_source.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ce1dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target Tokenizing\n",
    "tokenizer_target = Tokenizer(num_words= None,filters = '', lower=False)\n",
    "tokenizer_target.fit_on_texts(data.target_input)\n",
    "word_index_target = tokenizer_target.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77d34af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data sequencing\n",
    "encoder_input  = tokenizer_source.texts_to_sequences(data.source)\n",
    "\n",
    "# target sequencing\n",
    "decoder_input = tokenizer_target.texts_to_sequences(data.target_input)\n",
    "decoder_target= tokenizer_target.texts_to_sequences(data.target_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a83b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoder_input = pad_sequences(encoder_input, maxlen = max_src_len, padding = 'post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_tar_len, padding = 'post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_tar_len, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82acef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c9e97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련용 encoder\n",
    "encoder_inputs = layers.Input(shape=(None, len(word_index_source)+1))\n",
    "encoder_embedding = layers.Embedding()\n",
    "encoder_lstm = layers.LSTM(256, return_state = True)\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33aff170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련용 decoder\n",
    "decoder_inputs = layers.Input(shape = (None, len(word_index_target)+1))\n",
    "# decoder - output\n",
    "decoder_lstm = layers.LSTM(256, return_sequences = True, return_state = True)\n",
    "\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state= encoder_states)\n",
    "decoder_dense = layers.Dense(len(word_index_target)+1, activation = 'softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1243257b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 5s 95ms/step - loss: 3.2789 - val_loss: 2.5943\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 2.6311 - val_loss: 2.5444\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 2.5195 - val_loss: 2.5044\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 2.4659 - val_loss: 2.4695\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 2.4823 - val_loss: 2.3970\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 2.3664 - val_loss: 2.3440\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 2.3163 - val_loss: 2.2876\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 2.2594 - val_loss: 2.2506\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 2.2668 - val_loss: 2.2090\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 2.1646 - val_loss: 2.1685\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 2.1169 - val_loss: 2.1305\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 2.1169 - val_loss: 2.0749\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 2.0178 - val_loss: 2.0359\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 1.9850 - val_loss: 2.0019\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 1.9470 - val_loss: 1.9758\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 1.9238 - val_loss: 1.9367\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 1.8886 - val_loss: 1.9274\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.8593 - val_loss: 1.9016\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.8357 - val_loss: 1.8870\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.8025 - val_loss: 1.8958\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 1.7901 - val_loss: 1.8500\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 1.7685 - val_loss: 1.8239\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 1.7507 - val_loss: 1.8136\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.7330 - val_loss: 1.7983\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.7171 - val_loss: 1.7960\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.7031 - val_loss: 1.7843\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.6928 - val_loss: 1.7854\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.6946 - val_loss: 1.7694\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.6740 - val_loss: 1.7651\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.6733 - val_loss: 1.7389\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 1.6422 - val_loss: 1.7432\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.6379 - val_loss: 1.7243\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.6151 - val_loss: 1.7268\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.6081 - val_loss: 1.7118\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.5994 - val_loss: 1.6973\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.5848 - val_loss: 1.6857\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.5678 - val_loss: 1.6813\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 1.5625 - val_loss: 1.6880\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.5511 - val_loss: 1.6799\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.5357 - val_loss: 1.6935\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.5307 - val_loss: 1.6595\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.5195 - val_loss: 1.6619\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.5068 - val_loss: 1.6447\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.4963 - val_loss: 1.6579\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.4857 - val_loss: 1.6368\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.4757 - val_loss: 1.6368\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.4673 - val_loss: 1.6290\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 1.4540 - val_loss: 1.6225\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.4475 - val_loss: 1.6349\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.4322 - val_loss: 1.6166\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.4261 - val_loss: 1.6150\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.4136 - val_loss: 1.6076\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.4037 - val_loss: 1.5923\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.3941 - val_loss: 1.5974\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 1.3846 - val_loss: 1.6005\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.3735 - val_loss: 1.5870\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 1.3589 - val_loss: 1.5799\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.3540 - val_loss: 1.6058\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.3478 - val_loss: 1.5895\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.3326 - val_loss: 1.5822\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.3199 - val_loss: 1.5758\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.3093 - val_loss: 1.5950\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.3042 - val_loss: 1.5787\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.2952 - val_loss: 1.5783\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.2791 - val_loss: 1.5790\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.2684 - val_loss: 1.5728\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.2629 - val_loss: 1.5766\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.2545 - val_loss: 1.5705\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.2347 - val_loss: 1.5950\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.2324 - val_loss: 1.5863\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.2113 - val_loss: 1.5780\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.2067 - val_loss: 1.5744\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.2112 - val_loss: 1.5807\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.1887 - val_loss: 1.5825\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.1746 - val_loss: 1.6015\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.1662 - val_loss: 1.5849\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.1570 - val_loss: 1.5761\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.1447 - val_loss: 1.5887\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.1249 - val_loss: 1.5815\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.1325 - val_loss: 1.6322\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.1172 - val_loss: 1.5890\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.0891 - val_loss: 1.5874\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.0878 - val_loss: 1.5592\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.0643 - val_loss: 1.5953\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.0655 - val_loss: 1.6155\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.0433 - val_loss: 1.5789\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.1143 - val_loss: 1.7206\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.2147 - val_loss: 1.5854\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 1.0364 - val_loss: 1.5690\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.0087 - val_loss: 1.5452\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.9988 - val_loss: 1.5617\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1.0256 - val_loss: 1.5695\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.9709 - val_loss: 1.6388\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.9783 - val_loss: 1.5775\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.9465 - val_loss: 1.5581\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.9499 - val_loss: 1.6235\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.9418 - val_loss: 1.5630\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.9795 - val_loss: 1.6498\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.9444 - val_loss: 1.6518\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.9065 - val_loss: 1.6257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x207c789e808>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy')\n",
    "model.fit(x = [encoder_input, decoder_input], y = decoder_target, batch_size = 64, epochs = 100, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3da7e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction encoder\n",
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76d5b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction decoder\n",
    "decoder_state_input_h = layers.Input(shape = (256,))\n",
    "decoder_state_input_c = layers.Input(shape = (256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state= decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(inputs = [decoder_inputs]+ decoder_states_inputs, outputs = [decoder_outputs]+decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "869dc4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = dict((i,char) for char, i in word_index_source.items())\n",
    "index_to_tar = dict((i,char) for char, i in word_index_target.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c314de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq, verbose = 0)\n",
    "    target_seq = np.zeros((1,1,len(word_index_target)+1))\n",
    "    target_seq[0,0,word_index_target['\\t']] = 1.\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq]+states_value, verbose = 0)\n",
    "        sampled_token_index = np.argmax(output_tokens)\n",
    "        if (sampled_token_index ==0):\n",
    "            sampled_token_index = 1\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        if(sampled_char == '\\n' or len(decoded_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1,1,len(word_index_target)+1))\n",
    "        target_seq[0,0,sampled_token_index] = 1.\n",
    "        states_value = [h,c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28005121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장 :  난 오늘 밥을 먹고 공원에 갔어.\n",
      "정답 문장 :  I went to the park after eating today.\n",
      "번역기가 번역한 문장 :  I went to the beater thas will we hove in the  oou.\n",
      "-----------------------------------\n",
      "입력 문장 :  즐거운 마음을 가지고 학교에 갔어.\n",
      "정답 문장 :  I went to the school with pleasure.\n",
      "번역기가 번역한 문장 :  I went to the sippork with my friends to the monning.\n",
      "-----------------------------------\n",
      "입력 문장 :  오늘은 쇼핑을 하러 동대문을 갔어.\n",
      "정답 문장 :  I went to Dongdaemun to do some shopping.\n",
      "번역기가 번역한 문장 :  I went to the sippork with my friends to the monning.\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [450,451,452]:\n",
    "    input_seq = encoder_input[seq_index:seq_index+1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    \n",
    "    print(35*'-')\n",
    "    print('입력 문장 : ', data.source[seq_index])\n",
    "    print('정답 문장 : ', data.target[seq_index][:len(data.target[seq_index])])\n",
    "    print('번역기가 번역한 문장 : ',decoded_sentence[:len(decoded_sentence)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b382875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b4867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
