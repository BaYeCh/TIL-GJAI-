{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d74148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'C:/pytest/'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2f8c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OUT_PATH = path + 'data/'\n",
    "model_name = 'transformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9032842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(path + 'chatdata_small.csv',names=['Q','A','label'], sep= ',', header = 0, encoding= 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bc71c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63188eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13af0040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡!', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네', 'SD카드 망가졌어', 'SD카드 안돼', 'SNS 맞팔 왜 안하지ㅠㅠ', 'SNS 시간낭비인 거 아는데 매일 하는 중', 'SNS 시간낭비인데 자꾸 보게됨', 'SNS보면 나만 빼고 다 행복해보여', '가끔 궁금해', '가끔 뭐하는지 궁금해', '가끔은 혼자인게 좋다', '가난한 자의 설움', '가만 있어도 땀난다', '가상화폐 쫄딱 망함', '가스불 켜고 나갔어', '가스불 켜놓고 나온거 같아']\n",
      "['하루가 또 가네요.', '위로해 드립니다.', '여행은 언제나 좋죠.', '여행은 언제나 좋죠.', '눈살이 찌푸려지죠.', '다시 새로 사는 게 마음 편해요.', '다시 새로 사는 게 마음 편해요.', '잘 모르고 있을 수도 있어요.', '시간을 정하고 해보세요.', '시간을 정하고 해보세요.', '자랑하는 자리니까요.', '그 사람도 그럴 거예요.', '그 사람도 그럴 거예요.', '혼자를 즐기세요.', '돈은 다시 들어올 거예요.', '땀을 식혀주세요.', '어서 잊고 새출발 하세요.', '빨리 집에 돌아가서 끄고 나오세요.', '빨리 집에 돌아가서 끄고 나오세요.']\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = list(data['Q']), list(data['A'])\n",
    "print(inputs, outputs , sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb6c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouputs 시작기호와 종료기호 부착\n",
    "# 데이터 3종이 필요\n",
    "# source 언어 : encoder_input 1개 , target 언어 : decoder_input, decoder_target 2개\n",
    "# decoder_input 데이터의 시작에는 <sos>,  문장 끝에는 <eos>를 부착\n",
    "# decoder_target 데이터에는 <eos> 만 필요\n",
    "# 어절 분리가 되도록 <sos> 뒤에 공백, <eos> 앞에 공백을 둠\n",
    "outputs_input = data.A.apply(lambda x: '<SOS> '+x+' <EOS>')\n",
    "outputs_target = data.A.apply(lambda x : x+ ' <EOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dc68ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    <SOS> 그 사람도 그럴 거예요. <EOS>\n",
      "10      <SOS> 자랑하는 자리니까요. <EOS>\n",
      "9     <SOS> 시간을 정하고 해보세요. <EOS>\n",
      "4        <SOS> 눈살이 찌푸려지죠. <EOS>\n",
      "13        <SOS> 혼자를 즐기세요. <EOS>\n",
      "Name: A, dtype: object 15        땀을 식혀주세요. <EOS>\n",
      "8     시간을 정하고 해보세요. <EOS>\n",
      "13        혼자를 즐기세요. <EOS>\n",
      "10      자랑하는 자리니까요. <EOS>\n",
      "1         위로해 드립니다. <EOS>\n",
      "Name: A, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(outputs_input.sample(5), outputs_target.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "687c6762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 {'SOS': 1, 'EOS': 2, 'SNS': 3, '다시': 4, '거예요': 5, '3박4일': 6, '놀러가고': 7, '싶다': 8, 'SD카드': 9, '가끔': 10, '궁금해': 11, '가스불': 12, '여행은': 13, '언제나': 14, '좋죠': 15, '새로': 16, '사는': 17, '게': 18, '마음': 19, '편해요': 20, '시간을': 21, '정하고': 22, '해보세요': 23, '그': 24, '사람도': 25, '그럴': 26, '빨리': 27, '집에': 28, '돌아가서': 29, '끄고': 30, '나오세요': 31, '12시': 32, '땡': 33, '1지망': 34, '학교': 35, '떨어졌어': 36, '정도': 37, 'PPL': 38, '심하네': 39, '망가졌어': 40, '안돼': 41, '맞팔': 42, '왜': 43, '안하지ㅠㅠ': 44, '시간낭비인': 45, '거': 46, '아는데': 47, '매일': 48, '하는': 49, '중': 50, '시간낭비인데': 51, '자꾸': 52, '보게됨': 53, 'SNS보면': 54, '나만': 55, '빼고': 56, '다': 57, '행복해보여': 58, '뭐하는지': 59, '가끔은': 60, '혼자인게': 61, '좋다': 62, '가난한': 63, '자의': 64, '설움': 65, '가만': 66, '있어도': 67, '땀난다': 68, '가상화폐': 69, '쫄딱': 70, '망함': 71, '켜고': 72, '나갔어': 73, '켜놓고': 74, '나온거': 75, '같아': 76, '하루가': 77, '또': 78, '가네요': 79, '위로해': 80, '드립니다': 81, '눈살이': 82, '찌푸려지죠': 83, '잘': 84, '모르고': 85, '있을': 86, '수도': 87, '있어요': 88, '자랑하는': 89, '자리니까요': 90, '혼자를': 91, '즐기세요': 92, '돈은': 93, '들어올': 94, '땀을': 95, '식혀주세요': 96, '어서': 97, '잊고': 98, '새출발': 99, '하세요': 100}\n"
     ]
    }
   ],
   "source": [
    "# Data Tokenizing\n",
    "# 각 단어의 종류에 대해서 숫자값을 배당\n",
    "# 같은 언어 사이에서의 번역이므로, 어휘 목록을 구성하는 토크나이저는 하나만 필요\n",
    "# inputs 와 outputs를 결합\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "inputs_series = pd.Series(inputs)\n",
    "inputs_outputs = pd.concat([inputs_series, outputs_input], axis = 0)\n",
    "\n",
    "tokenizer = Tokenizer(num_words= None, char_level=False, lower= False)\n",
    "tokenizer.fit_on_texts(inputs_outputs)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(len(word_index), word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bd32f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/pytest/data/ -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "if os.path.exists(DATA_OUT_PATH + model_name):\n",
    "    print('{} -- Folder already exists \\n'.format(DATA_OUT_PATH))\n",
    "else:\n",
    "    os.makedirs(DATA_OUT_PATH + model_name, exist_ok = True)\n",
    "    print('Folder create complete \\n')\n",
    "\n",
    "with open(DATA_OUT_PATH + model_name + '/transformer.pickle','wb') as file:\n",
    "    pickle.dump(tokenizer, file, protocol= pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6110ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_dict = {\n",
    "    'encoder_input_pad': encoder_input_pad,\n",
    "    'decoder_input_pad': decoder_input_pad,\n",
    "    'decoder_target_pad': decoder_target_pad,\n",
    "    'sentence_max_length': sentence_max_length\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76b9f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/pytest/data/transformer/transformer_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(transformer_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "976bf334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12시 땡! [32, 33]\n",
      "1지망 학교 떨어졌어 [34, 35, 36]\n",
      "3박4일 놀러가고 싶다 [6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "# Data Sequencing\n",
    "# 배당된 숫자를 이용하여 각 문장의 문자를 숫자로 치환\n",
    "# source 언어 Sequencing\n",
    "encoder_input = tokenizer.texts_to_sequences(list(inputs))\n",
    "print(inputs[0], encoder_input[0])\n",
    "print(inputs[1], encoder_input[1])\n",
    "print(inputs[2], encoder_input[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e88bfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS> 하루가 또 가네요. <EOS> [1, 77, 78, 79, 2]\n",
      "하루가 또 가네요. <EOS> [77, 78, 79, 2]\n"
     ]
    }
   ],
   "source": [
    "# target 언어 Sequencing\n",
    "decoder_input = tokenizer.texts_to_sequences(list(outputs_input))\n",
    "decoder_target = tokenizer.texts_to_sequences(list(outputs_target))\n",
    "\n",
    "print(outputs_input[0], decoder_input[0])\n",
    "\n",
    "print(outputs_target[0], decoder_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5881296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장의 maxlen 설정\n",
    "# source와 target 문장 모두에서의 최대 길이 구하기\n",
    "sentence_max_length = inputs_outputs.apply(lambda x : len(x.split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b418c96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a00715ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoder_input_pad = pad_sequences(encoder_input, maxlen= sentence_max_length, padding='post')\n",
    "decoder_input_pad = pad_sequences(decoder_input, maxlen= sentence_max_length, padding='post')\n",
    "decoder_target_pad = pad_sequences(decoder_target, maxlen= sentence_max_length, padding= 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83b6b1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 8)\n",
      "1지망 학교 떨어졌어\n",
      "[34, 35, 36]\n",
      "[34 35 36  0  0  0  0  0]\n",
      "(19, 8)\n",
      "<SOS> 위로해 드립니다. <EOS>\n",
      "[1, 80, 81, 2]\n",
      "[ 1 80 81  2  0  0  0  0]\n",
      "(19, 8)\n",
      "위로해 드립니다. <EOS>\n",
      "[80, 81, 2]\n",
      "[80 81  2  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_pad.shape)\n",
    "print(inputs[1])\n",
    "print(encoder_input[1])\n",
    "print(encoder_input_pad[1])\n",
    "\n",
    "print(decoder_input_pad.shape)\n",
    "print(outputs_input[1])\n",
    "print(decoder_input[1])\n",
    "print(decoder_input_pad[1])\n",
    "\n",
    "print(decoder_target_pad.shape)\n",
    "print(outputs_target[1])\n",
    "print(decoder_target[1])\n",
    "print(decoder_target_pad[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ef517db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import enum\n",
    "import re\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "548419ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 사용\n",
    "# 실제에서는 이부분을 제외\n",
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ab20991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 특수 기호 처리\n",
    "PAD_INDEX = 0\n",
    "STD_INDEX = 1\n",
    "END_INDEX = 2\n",
    "\n",
    "# 변수명 변경\n",
    "index_inputs = encoder_input_pad\n",
    "index_outputs = decoder_input_pad\n",
    "index_targets = decoder_target_pad\n",
    "\n",
    "# prepro_configs (preprocessing configurations)\n",
    "char2idx_dict = word_index\n",
    "idx2char_dict = {y:x for x,y in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f338bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary 추가 및 변경\n",
    "# dict_ex[new_key] = dict_ex[old_key]\n",
    "# del dict_ex[old_key]\n",
    "char2idx_dict['<PAD>'] = 0 # padding 값 설정\n",
    "\n",
    "char2idx_dict['<SOS>'] = char2idx_dict['SOS']\n",
    "del char2idx_dict['SOS']\n",
    "\n",
    "char2idx_dict['<END>'] = char2idx_dict['EOS']\n",
    "del char2idx_dict['EOS']\n",
    "\n",
    "idx2char_dict[0] = '<PAD>'\n",
    "idx2char_dict[1] = '<SOS>'\n",
    "idx2char_dict[2] = '<END>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1867f721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char2idx': {'SNS': 3, '다시': 4, '거예요': 5, '3박4일': 6, '놀러가고': 7, '싶다': 8, 'SD카드': 9, '가끔': 10, '궁금해': 11, '가스불': 12, '여행은': 13, '언제나': 14, '좋죠': 15, '새로': 16, '사는': 17, '게': 18, '마음': 19, '편해요': 20, '시간을': 21, '정하고': 22, '해보세요': 23, '그': 24, '사람도': 25, '그럴': 26, '빨리': 27, '집에': 28, '돌아가서': 29, '끄고': 30, '나오세요': 31, '12시': 32, '땡': 33, '1지망': 34, '학교': 35, '떨어졌어': 36, '정도': 37, 'PPL': 38, '심하네': 39, '망가졌어': 40, '안돼': 41, '맞팔': 42, '왜': 43, '안하지ㅠㅠ': 44, '시간낭비인': 45, '거': 46, '아는데': 47, '매일': 48, '하는': 49, '중': 50, '시간낭비인데': 51, '자꾸': 52, '보게됨': 53, 'SNS보면': 54, '나만': 55, '빼고': 56, '다': 57, '행복해보여': 58, '뭐하는지': 59, '가끔은': 60, '혼자인게': 61, '좋다': 62, '가난한': 63, '자의': 64, '설움': 65, '가만': 66, '있어도': 67, '땀난다': 68, '가상화폐': 69, '쫄딱': 70, '망함': 71, '켜고': 72, '나갔어': 73, '켜놓고': 74, '나온거': 75, '같아': 76, '하루가': 77, '또': 78, '가네요': 79, '위로해': 80, '드립니다': 81, '눈살이': 82, '찌푸려지죠': 83, '잘': 84, '모르고': 85, '있을': 86, '수도': 87, '있어요': 88, '자랑하는': 89, '자리니까요': 90, '혼자를': 91, '즐기세요': 92, '돈은': 93, '들어올': 94, '땀을': 95, '식혀주세요': 96, '어서': 97, '잊고': 98, '새출발': 99, '하세요': 100, '<PAD>': 0, '<SOS>': 1, '<END>': 2}, 'idx2char': {1: '<SOS>', 2: '<END>', 3: 'SNS', 4: '다시', 5: '거예요', 6: '3박4일', 7: '놀러가고', 8: '싶다', 9: 'SD카드', 10: '가끔', 11: '궁금해', 12: '가스불', 13: '여행은', 14: '언제나', 15: '좋죠', 16: '새로', 17: '사는', 18: '게', 19: '마음', 20: '편해요', 21: '시간을', 22: '정하고', 23: '해보세요', 24: '그', 25: '사람도', 26: '그럴', 27: '빨리', 28: '집에', 29: '돌아가서', 30: '끄고', 31: '나오세요', 32: '12시', 33: '땡', 34: '1지망', 35: '학교', 36: '떨어졌어', 37: '정도', 38: 'PPL', 39: '심하네', 40: '망가졌어', 41: '안돼', 42: '맞팔', 43: '왜', 44: '안하지ㅠㅠ', 45: '시간낭비인', 46: '거', 47: '아는데', 48: '매일', 49: '하는', 50: '중', 51: '시간낭비인데', 52: '자꾸', 53: '보게됨', 54: 'SNS보면', 55: '나만', 56: '빼고', 57: '다', 58: '행복해보여', 59: '뭐하는지', 60: '가끔은', 61: '혼자인게', 62: '좋다', 63: '가난한', 64: '자의', 65: '설움', 66: '가만', 67: '있어도', 68: '땀난다', 69: '가상화폐', 70: '쫄딱', 71: '망함', 72: '켜고', 73: '나갔어', 74: '켜놓고', 75: '나온거', 76: '같아', 77: '하루가', 78: '또', 79: '가네요', 80: '위로해', 81: '드립니다', 82: '눈살이', 83: '찌푸려지죠', 84: '잘', 85: '모르고', 86: '있을', 87: '수도', 88: '있어요', 89: '자랑하는', 90: '자리니까요', 91: '혼자를', 92: '즐기세요', 93: '돈은', 94: '들어올', 95: '땀을', 96: '식혀주세요', 97: '어서', 98: '잊고', 99: '새출발', 100: '하세요', 0: '<PAD>'}, 'vocab_size': 101, 'pad_symbol': '<PAD>', 'std_symbol': '<SOS>', 'end_symbol': '<END>'}\n"
     ]
    }
   ],
   "source": [
    "prepro_configs = dict({'char2idx': char2idx_dict, 'idx2char': idx2char_dict, \n",
    "                      'vocab_size': len(word_index), 'pad_symbol':'<PAD>','std_symbol':'<SOS>',\n",
    "                      'end_symbol': '<END>'})\n",
    "print(prepro_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c93ed698",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = prepro_configs['char2idx']\n",
    "end_index = prepro_configs['end_symbol']\n",
    "vocab_size = prepro_configs['vocab_size']\n",
    "BATCH_SIZE = 2 \n",
    "MAX_SEQUENCE = 25\n",
    "EPOCHS = 30\n",
    "VALID_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8f9fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "kargs = {'model_name': model_name,\n",
    "         'num_layers': 2,\n",
    "         'd_model': 512, # 단어의 차원 = 임베딩 dimension\n",
    "         'num_heads':8,\n",
    "         'dff': 2048, # 출력층의 노드 수\n",
    "         'input_vocab_size': vocab_size, # 단어 사전의 수\n",
    "         'target_vocab_size': vocab_size, # 단어 사전의 수\n",
    "         'maximum_position_encoding': MAX_SEQUENCE, # 포지션 인코더의 최대 시퀀스 길이\n",
    "         'end_token_idx': char2idx[end_index], # 종료 표지의 인덱스\n",
    "         'rate' : 0.1 # Dropout에 사용되는 비율\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee7da03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순방향 마스크\n",
    "# seq의 값이 padding 0일 때만 1.0을 출력하고, 그 외에는 0을 출력하는 함수\n",
    "# 마스킹 대상을 1.0으로 만든다. 이후 -1e9라는 작은 수를 곱하고\n",
    "# 후에 softmax() 함수를 거쳐 값을 역전\n",
    "# 입력 2D -> return 4D\n",
    "def create_padding_mask(seq):\n",
    "    # seq 값이 0이면 1(true)를 출력하여  mask에 할당\n",
    "    mask = tf.cast(tf.math.equal(seq,0), tf.float32)\n",
    "    # 1D -> 3D로\n",
    "    return mask[:,tf.newaxis, tf.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "322e45b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삼각 행렬 만들기\n",
    "# 우삼각 부분만 1로 마스킹 영역을 표시\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1,0) # 하삼각행렬\n",
    "    # 하삼각행렬을 만든 후 1에서 빼서 역전시켜 상삼각 행렬을 만듦\n",
    "    return mask\n",
    "# create_padding_mask와 look_ahead_mask는 비슷한 모양\n",
    "# 자신의 뒤에 있는 단어나 패딩을 받는 부분은 보지 않기 위한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e48c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar): # (Encoder input, Decoder input)\n",
    "    # combined_mask 만드는 과정\n",
    "    enc_padding_mask = create_padding_mask(inp) # 인코더 패딩 마스크\n",
    "    dec_padding_mask = create_padding_mask(inp) # 디코더 두 번째 어텐션 블록에서 사용\n",
    "    \n",
    "    # 디코더의 첫 번째 어텐션 블록에서 사용되는 마스크\n",
    "    # 디코더가 받은 데이터를 패딩 처리 이후 순방향 마스킹을 하여 뒷 단어가 \n",
    "    # 참고되지 않도록 함\n",
    "    # combined_mask = look_ahead_mask 라는 이름으로 사용\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask,look_ahead_mask)\n",
    "                            # padding mask, subsequent mask\n",
    "    \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "    # 인코더 input 마스크(pad), 디코더 첫 번째 어텐션 마스크, 두 번째 어텐션 마스크(pad)\n",
    "                            # pad와 subse 중 해당되는 것으로 mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53e739fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_inputs : encoder_input_pad\n",
    "# index_ouputs : decoder_input_pad\n",
    "enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(index_inputs, index_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ac7b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "def get_angles(pos,i, d_model):\n",
    "    # post: 각 문장의 단어 길이만큼의 공간, 단어의 위치 정보 \n",
    "    # i : 각 단어가 갖는 차원 만큼의 공간, 단어의 정보를 기록할 공간\n",
    "    # d_model : 단어 차원 수 (현재 512)\n",
    "    angle_rates = 1/np.power(10000,(2*i//2)/np.float32(d_model))\n",
    "    # 각 단어의 표현 공간에 위치 정보\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70bb5311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:,np.newaxis],\n",
    "                           np.arange(d_model)[np.newaxis,:],\n",
    "                           d_model)\n",
    "    # 인덱스가 짝수인 경우 sin, 홀수인 경우 cos\n",
    "    angle_rads[:,0::2] = np.sin(angle_rads[:,0::2])\n",
    "    # 0번 부터 2개씩 건너뛰어 sin함수 적용\n",
    "    angle_rads[:,1::2] = np.cos(angle_rads[:,1::2])\n",
    "    # 1번 부터 2개씩 건너뛰어 cos함수 적용\n",
    "    pos_encoding = angle_rads[np.newaxis,...]\n",
    "    # ... : angle_rads의 차원을 그대로 가져옴\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07eaa417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q,k,v,mask):\n",
    "    matmul_qk = tf.matmul(q,k, transpose_b = True)# : attention score\n",
    "    # Q행렬과 전치된 K행렬을 내적 연산\n",
    "    # transpose_b : 두 번째 입력에 대해 전치 결정\n",
    "    # K 행렬의 차원 수 (열의 수)를 구한다.\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    # Key 벡터의 차원 수의 제곱근으로 나누어 크기를 줄임\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    \n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "    \n",
    "    # softmax 함수를 거쳐 매우작은 값은 0으로 마스킹 됨(우삼각)\n",
    "    # 자신보다 뒤에 나오는 단어는 참조하지 못함\n",
    "    # 그 외의 양의 값은 확률 정보가 됨(하삼각)\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis = -1)\n",
    "    # 패딩 마스크 순방향 마스크를 받을 부분은 -> 0\n",
    "    # 단어가 있는 자리는 양수 값을 기준\n",
    "    # 확률 값 Attention Score에 Value 벡터로 가중합을 수행\n",
    "    output = tf.matmul(attention_weights,v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc258e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super().__init__() # 부모의 기능 가져오기, Layers 클래스의 메서드 가져오기\n",
    "        self.num_heads = kargs['num_heads'] # 어텐션 헤드 수 8\n",
    "        self.d_model = kargs['d_model'] # 단어의 차원 수 512\n",
    "        \n",
    "        # assert구문은 문제 발생 시 알림 역할\n",
    "        assert self.d_model % self.num_heads ==0\n",
    "        # d_model의 차원 수는 헤드의 개수로 나머지 없이 나뉘어야 함\n",
    "        \n",
    "        self.depth = self.d_model // self.num_heads\n",
    "        # 각 헤드에 입력될 벡터의 차원 수를 둘을 나눈 몫으로 결정\n",
    "        \n",
    "        # query, key, value 가중치 레이어 설정\n",
    "        # input 결과를 받을 수 있도록 차원 수를 동일하게\n",
    "        self.wq = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wk = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wv = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        \n",
    "        # 셀프 어텐션 결과를 출력하기 위한 레이어\n",
    "        self.dense = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        \n",
    "    # 각 배치 사이즈마다 데이터가 [seq_len X depth]로 되어 있는 것을\n",
    "    # [num_heads X seq_len X depth]로 변환, 헤드 수 만큼 분리하는 함수\n",
    "    # (depth == d_model == 임베딩 차원)\n",
    "    def split_heads(self, x, batch_size):\n",
    "        # (batch_size, seq_len, depth) -> (batch_size, seq_len, num_heads, depth)\n",
    "        # seq_len는 -1로 표기하여 자동 배정\n",
    "        # 숫자가 기입된 부분의 축을 변환하고 난 뒤 남은 축의 형태는 원래 텐서의\n",
    "        # 총 크기와 같도록 자동으로 결정\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, depth)로 치환\n",
    "        return tf.transpose(x, perm = [0,1,2,3])\n",
    "        \n",
    "    # fit단계(훈련)에서 실행되는 함수\n",
    "    def call(self, v,k,q,mask):\n",
    "        batch_size = tf.shape(q)[0] # batch size를 구함\n",
    "        \n",
    "        # (batch_size, seq_len, d_model)\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "        \n",
    "        # (batch_size, num_heads, seq_len, depth)\n",
    "        # num_heads 별로 depth(임베딩 차원)를 갖게함\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        \n",
    "        # 스케일 내적 어텐션 수행\n",
    "        scaled_attention, attention_weight = scaled_dot_product_attention(q,k,v,mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm = [0,2,1,3])\n",
    "        \n",
    "        # 4D -> 3D 변환 (batch_size, seq_len, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        # 가중합 (어텐션 결과)\n",
    "        \n",
    "        output = self.dense(concat_attention)\n",
    "        \n",
    "        # attention_weigth : softmax를 거친 확률 정보\n",
    "        # 어텐션을 얼마나 적용시킬 것인지에 대한 정보\n",
    "        return output, attention_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e4a2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position-wise Feed Forward Network\n",
    "def feed_forward_network(**kargs):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(kargs['dff'], activation ='relu'),\n",
    "        tf.keras.layers.Dense(kargs['d_model'])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e618793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(**kargs)\n",
    "        self.ffn = feed_forward_network(**kargs)\n",
    "        \n",
    "        # 층 정규화(Layer Normalization)\n",
    "        # LayerNormalization은 같은 층별로 평균을 0, 표준편차 1로 정규화\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        # Dropout 레이어 생성\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        \n",
    "    def call(self,x, mask):\n",
    "        attn_output, _ = self.mha(x,x,x,mask)\n",
    "        # encoder_layer에서는 attention_weight를 받을 필요가 없음\n",
    "        attn_output = self.dropout1(attn_output) # Dropout 수행\n",
    "        out1 = self.layernorm1(x + attn_output) # Residual Connection & LayerNormalization\n",
    "        \n",
    "        ffn_output = self.ffn(out1) # out1에 대해 feed forward network\n",
    "        ffn_output = self.dropout2(ffn_output) # 드롭아웃 수행\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4969fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LayerNormalization example\n",
    "# data = np.array([0.006,0.002,0.004,0.009,0.005,0.076,0.007,0.008,0.003])\n",
    "# data = data.reshape(-1,3)\n",
    "# print(data)\n",
    "# layer = tf.keras.layers.LayerNormalization(axis = 1)\n",
    "# output = layer(data)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51bb4b9",
   "metadata": {},
   "source": [
    "# 디코더 레이어와 인코더 레이어\n",
    "1. init()에서 인코더와 다르게 멀티 헤드 어텐션을 두 번 수행하기 위한 준비를 함\n",
    "2. call()은 인코더의 결과를 받는 enc_output과 순방향 마스크 어텐션을 위해 look\n",
    "    ahead_mask를 추가로 받음\n",
    "3. call()에서 첫 번째 어텐션은 순방향 마스크 어텐션을 수행 (두 번째 어텐션을 동일한\n",
    "    padding_mask)\n",
    "4. call()에서 두 번째 어텐션은 v,k에 enc_output을 넣지만 q는 첫 번째 어텐션 결과\n",
    "    를 넣는다.\n",
    "\n",
    "\n",
    "+ 디코더의 query(직전 단어)와 인코더의 key(현재 단어)를 내적 연산(Q,K_transposed)하고, 그 결과에 대해 인코더의 value를 가중합 함\n",
    "    + 뒷 단어가 무엇이 올지 알 수 없는 디코더의 입장에서는 context_vector로서 다음 단어를 예측할 수 있는 이코더의 정보를 활용 가능\n",
    "    + 두 번째 어텐션에서는 뒤쪽을 보지 않는 순방향 마스크를 사용하면 안됨\n",
    "    + 인코더처럼 패딩 마스크만 사용해야 함\n",
    "+ 직전 단어의 내용을 참조하여 이번에 나올 단어가 무엇인지를 알게 해주는 것\n",
    "Q : 찾고자 하는 단어 : 직전 단어\n",
    "K : 사전에 등록된 단어 : 기학습된 내용을 참조하여 어떤 단어에 집중해야 (유사한지) \n",
    "알려주는 기능\n",
    "V : 단어의 의미 : 현재 단어의 K의 내용을 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "864689e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(**kargs)\n",
    "        self.mha2 = MultiHeadAttention(**kargs)\n",
    "        self.ffn = feed_forward_network(**kargs)\n",
    "        \n",
    "        # 층 정규화\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        # Dropout 레이어 생성\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout3 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        \n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x,x,x,look_ahead_mask)\n",
    "        # look_ahead_mask : pad + subsequent, attn_weight_block1 : 확률로 된 어텐션 스코어\n",
    "        # attn1 : 가중합, attention을 적용한 벡터\n",
    "        attn1 = self.dropout1(attn1)\n",
    "        out1 = self.layernorm1(attn1 + x) # 잔차 연결 및 층 정규화 수행\n",
    "        \n",
    "        # 멀티 헤드 어텐션 레이어 2 수행\n",
    "                                                # k            v        q\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "        \n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        out3 = self.layernorm3(ffn_output +out2)\n",
    "        \n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9a9a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 모듈\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    '''\n",
    "        - 현재 단어의 임베딩 차원은 512, 사용할 인코더 레이어의 개수 2개\n",
    "        - 워드 임베딩은 케라스 이용, Flatten하지 않아 input_length 불필요\n",
    "        - 인코더 레이어 전체 연산 여러 번 반복\n",
    "        - 드롭아웃 레이어는 옵션\n",
    "    '''\n",
    "    def __init__(self, **kargs):\n",
    "        super().__init__()\n",
    "        self.d_model = kargs['d_model'] # 단어 임베딩 차원\n",
    "        self.num_layers = kargs['num_layers'] # 사용할 인코더 레이어 개수\n",
    "        \n",
    "        # 워드 임베딩 레이어 생성\n",
    "        # input_dim, output_dim, input_length / input_length는 Flatten이 없으면 생략 가능\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim = kargs['input_vocab_size'], output_dim = self.d_model)\n",
    "        \n",
    "        # 포지셔널 인코딩 레이어 생성\n",
    "        self.pos_encoding = positional_encoding(position = kargs['maximum_position_encoding'], d_model = self.d_model)\n",
    "        \n",
    "        # 인코더 레이어 생성 num_layers 수만큼 리스트 배열로 만든다\n",
    "        self.enc_layers = [EncoderLayer(**kargs) for _ in range(self.num_layers)]\n",
    "        \n",
    "        # 드롭아웃 레이어 생성\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "    \n",
    "    def call(self, x, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        # 가중치 곱하기(옵션) 각 워드 임베딩에 대해 스케일을 맞추는 과정\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:,:seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 인코더 레이어 연산을 반복하는 부분\n",
    "        # __init__()함수에서 생성된 복수의 인코더 레이어에 대하여 실제 수행\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecdd8c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 모듈\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    '''\n",
    "        두 번의 어텐션에서 나온 가중치를 block1과 block2로 받아 \n",
    "        attention_weights에 묶어 출력한다.\n",
    "        그러나 사용하지는 않음\n",
    "    '''\n",
    "    def __init__(self, **kargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = kargs['d_model']\n",
    "        self.num_layers = kargs['num_layers']\n",
    "        \n",
    "        # 워드 임베딩 레이어 생성\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim= kargs['target_vocab_size'], output_dim = self.d_model)\n",
    "        \n",
    "        # 포지셔널 인코딩 레이어 생성\n",
    "        self.pos_encoding = positional_encoding(position= kargs['maximum_position_encoding'], d_model = self.d_model)\n",
    "        \n",
    "        # 디코더 레이어 생성, num_layers 수만큼 리스트 배열로 만듦\n",
    "        self.dec_layers = [DecoderLayer(**kargs) for _ in range(self.num_layers)]\n",
    "        \n",
    "        # 드롭 아웃 레이어 생성\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        \n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:,:seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            # block1, block2 : attention score\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "            \n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "999a1581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머 구현\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, **kargs):\n",
    "        super().__init__(name = kargs['model_name'])\n",
    "        self.end_token_idx = kargs['end_token_idx']\n",
    "        \n",
    "        self.encoder = Encoder(**kargs)\n",
    "        self.decoder = Decoder(**kargs)\n",
    "        \n",
    "        self.final_layer = tf.keras.layers.Dense(kargs['target_vocab_size'])\n",
    "    \n",
    "    def call(self, x):\n",
    "        inp, tar = x\n",
    "        \n",
    "        # 인코더 패딩 마스크, 디코더 순방향 마스크, 디코더 패딩 마스크 생성\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "        \n",
    "        # 인코더 결과 출력 (batch_size, inp_seq_len, d_model)\n",
    "        enc_output = self.encoder(inp, enc_padding_mask)\n",
    "        \n",
    "        # 디코더 결과 출력\n",
    "        dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "        \n",
    "        # batch_size, tar_seq_len, target_vocab_size\n",
    "        final_output = self.final_layer(dec_output)\n",
    "        \n",
    "        return final_output\n",
    "    \n",
    "    def inference(self, x):\n",
    "        inp = x\n",
    "        tar = tf.expand_dims([STD_INDEX], axis = 0)\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "        \n",
    "        enc_output = self.encoder(inp, enc_padding_mask)\n",
    "        \n",
    "        predict_tokens = list()\n",
    "        for t in range(0, MAX_SEQUENCE):\n",
    "            dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "            final_output = self.final_layer(dec_output)\n",
    "            outputs = tf.argmax(final_output, axis = -1).numpy()\n",
    "            print('outputs:',outputs)\n",
    "            pred_token = outputs[0][-1]\n",
    "            \n",
    "            if pred_token == self.end_token_idx:\n",
    "                break\n",
    "            predict_tokens.append(pred_token)\n",
    "            tar = tf.expand_dims([STD_INDEX]+ predict_tokens, axis=0)\n",
    "            _, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "        return predict_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d697f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_logits : True  softmax함수를 거친 값이 아닌 일반 값이 필요함\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0bbeebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 정의\n",
    "# <PAD> 0은 손실값 계산에서 제외해야 하는데 일반 손실함수는 이를 예외로 두지 않아\n",
    "# 새로 구현\n",
    "def loss(real, pred):\n",
    "    # 들어온 값이 0이면 True, 이를 False(0)로 변환하여 이후 계산에서 제외\n",
    "    mask = tf.math.logical_not(tf.math.equal(real,0))\n",
    "    \n",
    "    loss_ = loss_object(real,pred)\n",
    "    mask = tf.cast(mask, dtype = loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    # reduce_mean : 차원을 감소시킴, 차원과 관계없이 요소들의 평균값을 계산\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eac288e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 함수 정의\n",
    "def accuracy(real,pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real,0))\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype = pred.dtype), axis = -1)\n",
    "    pred *= mask\n",
    "    acc = train_accuracy(real, pred)\n",
    "    \n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47708a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(**kargs)\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(1e-4), loss = loss, metrics = [accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "500d60e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists\n"
     ]
    }
   ],
   "source": [
    "# EarlyStopping\n",
    "earlystop_callback = EarlyStopping(monitor= 'val_accuracy', min_delta = 0.0001, patience = 10)\n",
    "\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weight.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print('already exists')\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok= True)\n",
    "    print('create complete')\n",
    "    \n",
    "checkpointer = ModelCheckpoint(checkpoint_path, monitor= 'val_accuracy', verbose = 1, save_best_only= True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3602afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 1.9872 - accuracy: 0.4473\n",
      "Epoch 1: val_accuracy improved from -inf to 0.47368, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 12s 160ms/step - loss: 1.7947 - accuracy: 0.4582 - val_loss: 3.2421 - val_accuracy: 0.4737\n",
      "Epoch 2/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.8515 - accuracy: 0.5131\n",
      "Epoch 2: val_accuracy improved from 0.47368 to 0.53618, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.8509 - accuracy: 0.5200 - val_loss: 3.2856 - val_accuracy: 0.5362\n",
      "Epoch 3/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.5577 - accuracy: 0.5745\n",
      "Epoch 3: val_accuracy improved from 0.53618 to 0.59868, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.5244 - accuracy: 0.5824 - val_loss: 3.4645 - val_accuracy: 0.5987\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2752 - accuracy: 0.6427\n",
      "Epoch 4: val_accuracy improved from 0.59868 to 0.66283, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2752 - accuracy: 0.6427 - val_loss: 3.4477 - val_accuracy: 0.6628\n",
      "Epoch 5/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.1358 - accuracy: 0.6907\n",
      "Epoch 5: val_accuracy improved from 0.66283 to 0.71184, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1246 - accuracy: 0.6966 - val_loss: 3.3991 - val_accuracy: 0.7118\n",
      "Epoch 6/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0666 - accuracy: 0.7335\n",
      "Epoch 6: val_accuracy improved from 0.71184 to 0.74781, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0729 - accuracy: 0.7379 - val_loss: 3.3713 - val_accuracy: 0.7478\n",
      "Epoch 7/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0499 - accuracy: 0.7638\n",
      "Epoch 7: val_accuracy improved from 0.74781 to 0.77256, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0507 - accuracy: 0.7670 - val_loss: 3.3192 - val_accuracy: 0.7726\n",
      "Epoch 8/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.7880\n",
      "Epoch 8: val_accuracy improved from 0.77256 to 0.79276, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0214 - accuracy: 0.7880 - val_loss: 3.2857 - val_accuracy: 0.7928\n",
      "Epoch 9/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0118 - accuracy: 0.8030\n",
      "Epoch 9: val_accuracy improved from 0.79276 to 0.80848, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0111 - accuracy: 0.8052 - val_loss: 3.3138 - val_accuracy: 0.8085\n",
      "Epoch 10/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0112 - accuracy: 0.8169\n",
      "Epoch 10: val_accuracy improved from 0.80848 to 0.82105, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.0113 - accuracy: 0.8188 - val_loss: 3.3512 - val_accuracy: 0.8211\n",
      "Epoch 11/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.8298\n",
      "Epoch 11: val_accuracy improved from 0.82105 to 0.83134, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0085 - accuracy: 0.8298 - val_loss: 3.3936 - val_accuracy: 0.8313\n",
      "Epoch 12/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0101 - accuracy: 0.8375\n",
      "Epoch 12: val_accuracy improved from 0.83134 to 0.83991, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.0090 - accuracy: 0.8389 - val_loss: 3.4076 - val_accuracy: 0.8399\n",
      "Epoch 13/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0058 - accuracy: 0.8453\n",
      "Epoch 13: val_accuracy improved from 0.83991 to 0.84717, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0059 - accuracy: 0.8465 - val_loss: 3.4213 - val_accuracy: 0.8472\n",
      "Epoch 14/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.8530\n",
      "Epoch 14: val_accuracy improved from 0.84717 to 0.85338, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0063 - accuracy: 0.8530 - val_loss: 3.4508 - val_accuracy: 0.8534\n",
      "Epoch 15/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.8586\n",
      "Epoch 15: val_accuracy improved from 0.85338 to 0.85877, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0053 - accuracy: 0.8586 - val_loss: 3.4852 - val_accuracy: 0.8588\n",
      "Epoch 16/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.8635\n",
      "Epoch 16: val_accuracy improved from 0.85877 to 0.86349, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0041 - accuracy: 0.8635 - val_loss: 3.5065 - val_accuracy: 0.8635\n",
      "Epoch 17/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0045 - accuracy: 0.8670\n",
      "Epoch 17: val_accuracy improved from 0.86349 to 0.86765, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.0042 - accuracy: 0.8678 - val_loss: 3.5099 - val_accuracy: 0.8676\n",
      "Epoch 18/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0041 - accuracy: 0.8708\n",
      "Epoch 18: val_accuracy improved from 0.86765 to 0.87135, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0041 - accuracy: 0.8715 - val_loss: 3.5133 - val_accuracy: 0.8713\n",
      "Epoch 19/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0040 - accuracy: 0.8743\n",
      "Epoch 19: val_accuracy improved from 0.87135 to 0.87465, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.0037 - accuracy: 0.8749 - val_loss: 3.5169 - val_accuracy: 0.8747\n",
      "Epoch 20/30\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.0033 - accuracy: 0.8777\n",
      "Epoch 20: val_accuracy improved from 0.87465 to 0.87763, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0035 - accuracy: 0.8780 - val_loss: 3.5250 - val_accuracy: 0.8776\n",
      "Epoch 21/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0026 - accuracy: 0.8801\n",
      "Epoch 21: val_accuracy improved from 0.87763 to 0.88033, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0026 - accuracy: 0.8807 - val_loss: 3.5335 - val_accuracy: 0.8803\n",
      "Epoch 22/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0026 - accuracy: 0.8827\n",
      "Epoch 22: val_accuracy improved from 0.88033 to 0.88278, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.0025 - accuracy: 0.8832 - val_loss: 3.5334 - val_accuracy: 0.8828\n",
      "Epoch 23/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0023 - accuracy: 0.8850\n",
      "Epoch 23: val_accuracy improved from 0.88278 to 0.88501, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0026 - accuracy: 0.8855 - val_loss: 3.5383 - val_accuracy: 0.8850\n",
      "Epoch 24/30\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.0028 - accuracy: 0.8873\n",
      "Epoch 24: val_accuracy improved from 0.88501 to 0.88706, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0027 - accuracy: 0.8875 - val_loss: 3.5437 - val_accuracy: 0.8871\n",
      "Epoch 25/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0032 - accuracy: 0.8890\n",
      "Epoch 25: val_accuracy improved from 0.88706 to 0.88895, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0031 - accuracy: 0.8894 - val_loss: 3.5537 - val_accuracy: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0021 - accuracy: 0.8908\n",
      "Epoch 26: val_accuracy improved from 0.88895 to 0.89069, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.0021 - accuracy: 0.8912 - val_loss: 3.5561 - val_accuracy: 0.8907\n",
      "Epoch 27/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0022 - accuracy: 0.8924\n",
      "Epoch 27: val_accuracy improved from 0.89069 to 0.89230, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0022 - accuracy: 0.8928 - val_loss: 3.5617 - val_accuracy: 0.8923\n",
      "Epoch 28/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0019 - accuracy: 0.8939\n",
      "Epoch 28: val_accuracy improved from 0.89230 to 0.89380, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0020 - accuracy: 0.8943 - val_loss: 3.5662 - val_accuracy: 0.8938\n",
      "Epoch 29/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0022 - accuracy: 0.8954\n",
      "Epoch 29: val_accuracy improved from 0.89380 to 0.89519, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0022 - accuracy: 0.8957 - val_loss: 3.5709 - val_accuracy: 0.8952\n",
      "Epoch 30/30\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0016 - accuracy: 0.8967\n",
      "Epoch 30: val_accuracy improved from 0.89519 to 0.89649, saving model to C:/pytest/data/transformer\\weight.h5\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0015 - accuracy: 0.8970 - val_loss: 3.5868 - val_accuracy: 0.8965\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([index_inputs, index_outputs], index_targets,\n",
    "                   batch_size= BATCH_SIZE, epochs= EPOCHS,\n",
    "                   validation_split=VALID_SPLIT, callbacks= [earlystop_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a2afdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.xlabel('EPOCHS')\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string,'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "22a06aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f12f78e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
