{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ccf9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'C:/pytest/'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fdeed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OUT_PATH = path + 'data/'\n",
    "model_name = 'transformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b63c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(path + 'chatdata_small.csv',names=['Q','A','label'], sep= ',', header = 0, encoding= 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3437a51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11aa462d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b595bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡!', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네', 'SD카드 망가졌어', 'SD카드 안돼', 'SNS 맞팔 왜 안하지ㅠㅠ', 'SNS 시간낭비인 거 아는데 매일 하는 중', 'SNS 시간낭비인데 자꾸 보게됨', 'SNS보면 나만 빼고 다 행복해보여', '가끔 궁금해', '가끔 뭐하는지 궁금해', '가끔은 혼자인게 좋다', '가난한 자의 설움', '가만 있어도 땀난다', '가상화폐 쫄딱 망함', '가스불 켜고 나갔어', '가스불 켜놓고 나온거 같아']\n",
      "['하루가 또 가네요.', '위로해 드립니다.', '여행은 언제나 좋죠.', '여행은 언제나 좋죠.', '눈살이 찌푸려지죠.', '다시 새로 사는 게 마음 편해요.', '다시 새로 사는 게 마음 편해요.', '잘 모르고 있을 수도 있어요.', '시간을 정하고 해보세요.', '시간을 정하고 해보세요.', '자랑하는 자리니까요.', '그 사람도 그럴 거예요.', '그 사람도 그럴 거예요.', '혼자를 즐기세요.', '돈은 다시 들어올 거예요.', '땀을 식혀주세요.', '어서 잊고 새출발 하세요.', '빨리 집에 돌아가서 끄고 나오세요.', '빨리 집에 돌아가서 끄고 나오세요.']\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = list(data['Q']), list(data['A'])\n",
    "print(inputs, outputs , sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d44a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouputs 시작기호와 종료기호 부착\n",
    "# 데이터 3종이 필요\n",
    "# source 언어 : encoder_input 1개 , target 언어 : decoder_input, decoder_target 2개\n",
    "# decoder_input 데이터의 시작에는 <sos>,  문장 끝에는 <eos>를 부착\n",
    "# decoder_target 데이터에는 <eos> 만 필요\n",
    "# 어절 분리가 되도록 <sos> 뒤에 공백, <eos> 앞에 공백을 둠\n",
    "outputs_input = data.A.apply(lambda x: '<SOS> '+x+' <EOS>')\n",
    "outputs_target = data.A.apply(lambda x : x+ ' <EOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4aad726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5      <SOS> 다시 새로 사는 게 마음 편해요. <EOS>\n",
      "9           <SOS> 시간을 정하고 해보세요. <EOS>\n",
      "17    <SOS> 빨리 집에 돌아가서 끄고 나오세요. <EOS>\n",
      "2             <SOS> 여행은 언제나 좋죠. <EOS>\n",
      "12          <SOS> 그 사람도 그럴 거예요. <EOS>\n",
      "Name: A, dtype: object 2             여행은 언제나 좋죠. <EOS>\n",
      "17    빨리 집에 돌아가서 끄고 나오세요. <EOS>\n",
      "18    빨리 집에 돌아가서 끄고 나오세요. <EOS>\n",
      "12          그 사람도 그럴 거예요. <EOS>\n",
      "6      다시 새로 사는 게 마음 편해요. <EOS>\n",
      "Name: A, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(outputs_input.sample(5), outputs_target.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac7c8b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 {'SOS': 1, 'EOS': 2, 'SNS': 3, '다시': 4, '거예요': 5, '3박4일': 6, '놀러가고': 7, '싶다': 8, 'SD카드': 9, '가끔': 10, '궁금해': 11, '가스불': 12, '여행은': 13, '언제나': 14, '좋죠': 15, '새로': 16, '사는': 17, '게': 18, '마음': 19, '편해요': 20, '시간을': 21, '정하고': 22, '해보세요': 23, '그': 24, '사람도': 25, '그럴': 26, '빨리': 27, '집에': 28, '돌아가서': 29, '끄고': 30, '나오세요': 31, '12시': 32, '땡': 33, '1지망': 34, '학교': 35, '떨어졌어': 36, '정도': 37, 'PPL': 38, '심하네': 39, '망가졌어': 40, '안돼': 41, '맞팔': 42, '왜': 43, '안하지ㅠㅠ': 44, '시간낭비인': 45, '거': 46, '아는데': 47, '매일': 48, '하는': 49, '중': 50, '시간낭비인데': 51, '자꾸': 52, '보게됨': 53, 'SNS보면': 54, '나만': 55, '빼고': 56, '다': 57, '행복해보여': 58, '뭐하는지': 59, '가끔은': 60, '혼자인게': 61, '좋다': 62, '가난한': 63, '자의': 64, '설움': 65, '가만': 66, '있어도': 67, '땀난다': 68, '가상화폐': 69, '쫄딱': 70, '망함': 71, '켜고': 72, '나갔어': 73, '켜놓고': 74, '나온거': 75, '같아': 76, '하루가': 77, '또': 78, '가네요': 79, '위로해': 80, '드립니다': 81, '눈살이': 82, '찌푸려지죠': 83, '잘': 84, '모르고': 85, '있을': 86, '수도': 87, '있어요': 88, '자랑하는': 89, '자리니까요': 90, '혼자를': 91, '즐기세요': 92, '돈은': 93, '들어올': 94, '땀을': 95, '식혀주세요': 96, '어서': 97, '잊고': 98, '새출발': 99, '하세요': 100}\n"
     ]
    }
   ],
   "source": [
    "# Data Tokenizing\n",
    "# 각 단어의 종류에 대해서 숫자값을 배당\n",
    "# 같은 언어 사이에서의 번역이므로, 어휘 목록을 구성하는 토크나이저는 하나만 필요\n",
    "# inputs 와 outputs를 결합\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "inputs_series = pd.Series(inputs)\n",
    "inputs_outputs = pd.concat([inputs_series, outputs_input], axis = 0)\n",
    "\n",
    "tokenizer = Tokenizer(num_words= None, char_level=False, lower= False)\n",
    "tokenizer.fit_on_texts(inputs_outputs)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(len(word_index), word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22f4d13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/pytest/data/ -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "if os.path.exists(DATA_OUT_PATH + model_name):\n",
    "    print('{} -- Folder already exists \\n'.format(DATA_OUT_PATH))\n",
    "else:\n",
    "    os.makedirs(DATA_OUT_PATH + model_name, exist_ok = True)\n",
    "    print('Folder create complete \\n')\n",
    "\n",
    "with open(DATA_OUT_PATH + model_name + '/transformer.pickle','wb') as file:\n",
    "    pickle.dump(tokenizer, file, protocol= pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "832418eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12시 땡! [32, 33]\n",
      "1지망 학교 떨어졌어 [34, 35, 36]\n",
      "3박4일 놀러가고 싶다 [6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "# Data Sequencing\n",
    "# 배당된 숫자를 이용하여 각 문장의 문자를 숫자로 치환\n",
    "# source 언어 Sequencing\n",
    "encoder_input = tokenizer.texts_to_sequences(list(inputs))\n",
    "print(inputs[0], encoder_input[0])\n",
    "print(inputs[1], encoder_input[1])\n",
    "print(inputs[2], encoder_input[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "823407bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS> 하루가 또 가네요. <EOS> [1, 77, 78, 79, 2]\n",
      "하루가 또 가네요. <EOS> [77, 78, 79, 2]\n"
     ]
    }
   ],
   "source": [
    "# target 언어 Sequencing\n",
    "decoder_input = tokenizer.texts_to_sequences(list(outputs_input))\n",
    "decoder_target = tokenizer.texts_to_sequences(list(outputs_target))\n",
    "\n",
    "print(outputs_input[0], decoder_input[0])\n",
    "\n",
    "print(outputs_target[0], decoder_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d69d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장의 maxlen 설정\n",
    "# source와 target 문장 모두에서의 최대 길이 구하기\n",
    "sentence_max_length = inputs_outputs.apply(lambda x : len(x.split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e72db8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b5ca73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoder_input_pad = pad_sequences(encoder_input, maxlen= sentence_max_length, padding='post')\n",
    "decoder_input_pad = pad_sequences(decoder_input, maxlen= sentence_max_length, padding='post')\n",
    "decoder_target_pad = pad_sequences(decoder_target, maxlen= sentence_max_length, padding= 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16ba2100",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_dict = {\n",
    "    'encoder_input_pad': encoder_input_pad,\n",
    "    'decoder_input_pad': decoder_input_pad,\n",
    "    'decoder_target_pad': decoder_target_pad,\n",
    "    'sentence_max_length': sentence_max_length\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08acc001",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/pytest/data/transformer/transformer_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(transformer_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c17cc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 8)\n",
      "1지망 학교 떨어졌어\n",
      "[34, 35, 36]\n",
      "[34 35 36  0  0  0  0  0]\n",
      "(19, 8)\n",
      "<SOS> 위로해 드립니다. <EOS>\n",
      "[1, 80, 81, 2]\n",
      "[ 1 80 81  2  0  0  0  0]\n",
      "(19, 8)\n",
      "위로해 드립니다. <EOS>\n",
      "[80, 81, 2]\n",
      "[80 81  2  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_pad.shape)\n",
    "print(inputs[1])\n",
    "print(encoder_input[1])\n",
    "print(encoder_input_pad[1])\n",
    "\n",
    "print(decoder_input_pad.shape)\n",
    "print(outputs_input[1])\n",
    "print(decoder_input[1])\n",
    "print(decoder_input_pad[1])\n",
    "\n",
    "print(decoder_target_pad.shape)\n",
    "print(outputs_target[1])\n",
    "print(decoder_target[1])\n",
    "print(decoder_target_pad[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29c94643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import enum\n",
    "import re\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "833685d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 사용\n",
    "# 실제에서는 이부분을 제외\n",
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2665590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 특수 기호 처리\n",
    "PAD_INDEX = 0\n",
    "STD_INDEX = 1\n",
    "END_INDEX = 2\n",
    "\n",
    "# 변수명 변경\n",
    "index_inputs = encoder_input_pad\n",
    "index_outputs = decoder_input_pad\n",
    "index_targets = decoder_target_pad\n",
    "\n",
    "# prepro_configs (preprocessing configurations)\n",
    "char2idx_dict = word_index\n",
    "idx2char_dict = {y:x for x,y in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68d62889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary 추가 및 변경\n",
    "# dict_ex[new_key] = dict_ex[old_key]\n",
    "# del dict_ex[old_key]\n",
    "char2idx_dict['<PAD>'] = 0 # padding 값 설정\n",
    "\n",
    "char2idx_dict['<SOS>'] = char2idx_dict['SOS']\n",
    "del char2idx_dict['SOS']\n",
    "\n",
    "char2idx_dict['<END>'] = char2idx_dict['EOS']\n",
    "del char2idx_dict['EOS']\n",
    "\n",
    "idx2char_dict[0] = '<PAD>'\n",
    "idx2char_dict[1] = '<SOS>'\n",
    "idx2char_dict[2] = '<END>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09d30d6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char2idx': {'SNS': 3, '다시': 4, '거예요': 5, '3박4일': 6, '놀러가고': 7, '싶다': 8, 'SD카드': 9, '가끔': 10, '궁금해': 11, '가스불': 12, '여행은': 13, '언제나': 14, '좋죠': 15, '새로': 16, '사는': 17, '게': 18, '마음': 19, '편해요': 20, '시간을': 21, '정하고': 22, '해보세요': 23, '그': 24, '사람도': 25, '그럴': 26, '빨리': 27, '집에': 28, '돌아가서': 29, '끄고': 30, '나오세요': 31, '12시': 32, '땡': 33, '1지망': 34, '학교': 35, '떨어졌어': 36, '정도': 37, 'PPL': 38, '심하네': 39, '망가졌어': 40, '안돼': 41, '맞팔': 42, '왜': 43, '안하지ㅠㅠ': 44, '시간낭비인': 45, '거': 46, '아는데': 47, '매일': 48, '하는': 49, '중': 50, '시간낭비인데': 51, '자꾸': 52, '보게됨': 53, 'SNS보면': 54, '나만': 55, '빼고': 56, '다': 57, '행복해보여': 58, '뭐하는지': 59, '가끔은': 60, '혼자인게': 61, '좋다': 62, '가난한': 63, '자의': 64, '설움': 65, '가만': 66, '있어도': 67, '땀난다': 68, '가상화폐': 69, '쫄딱': 70, '망함': 71, '켜고': 72, '나갔어': 73, '켜놓고': 74, '나온거': 75, '같아': 76, '하루가': 77, '또': 78, '가네요': 79, '위로해': 80, '드립니다': 81, '눈살이': 82, '찌푸려지죠': 83, '잘': 84, '모르고': 85, '있을': 86, '수도': 87, '있어요': 88, '자랑하는': 89, '자리니까요': 90, '혼자를': 91, '즐기세요': 92, '돈은': 93, '들어올': 94, '땀을': 95, '식혀주세요': 96, '어서': 97, '잊고': 98, '새출발': 99, '하세요': 100, '<PAD>': 0, '<SOS>': 1, '<END>': 2}, 'idx2char': {1: '<SOS>', 2: '<END>', 3: 'SNS', 4: '다시', 5: '거예요', 6: '3박4일', 7: '놀러가고', 8: '싶다', 9: 'SD카드', 10: '가끔', 11: '궁금해', 12: '가스불', 13: '여행은', 14: '언제나', 15: '좋죠', 16: '새로', 17: '사는', 18: '게', 19: '마음', 20: '편해요', 21: '시간을', 22: '정하고', 23: '해보세요', 24: '그', 25: '사람도', 26: '그럴', 27: '빨리', 28: '집에', 29: '돌아가서', 30: '끄고', 31: '나오세요', 32: '12시', 33: '땡', 34: '1지망', 35: '학교', 36: '떨어졌어', 37: '정도', 38: 'PPL', 39: '심하네', 40: '망가졌어', 41: '안돼', 42: '맞팔', 43: '왜', 44: '안하지ㅠㅠ', 45: '시간낭비인', 46: '거', 47: '아는데', 48: '매일', 49: '하는', 50: '중', 51: '시간낭비인데', 52: '자꾸', 53: '보게됨', 54: 'SNS보면', 55: '나만', 56: '빼고', 57: '다', 58: '행복해보여', 59: '뭐하는지', 60: '가끔은', 61: '혼자인게', 62: '좋다', 63: '가난한', 64: '자의', 65: '설움', 66: '가만', 67: '있어도', 68: '땀난다', 69: '가상화폐', 70: '쫄딱', 71: '망함', 72: '켜고', 73: '나갔어', 74: '켜놓고', 75: '나온거', 76: '같아', 77: '하루가', 78: '또', 79: '가네요', 80: '위로해', 81: '드립니다', 82: '눈살이', 83: '찌푸려지죠', 84: '잘', 85: '모르고', 86: '있을', 87: '수도', 88: '있어요', 89: '자랑하는', 90: '자리니까요', 91: '혼자를', 92: '즐기세요', 93: '돈은', 94: '들어올', 95: '땀을', 96: '식혀주세요', 97: '어서', 98: '잊고', 99: '새출발', 100: '하세요', 0: '<PAD>'}, 'vocab_size': 101, 'pad_symbol': '<PAD>', 'std_symbol': '<SOS>', 'end_symbol': '<END>'}\n"
     ]
    }
   ],
   "source": [
    "prepro_configs = dict({'char2idx': char2idx_dict, 'idx2char': idx2char_dict, \n",
    "                      'vocab_size': len(word_index), 'pad_symbol':'<PAD>','std_symbol':'<SOS>',\n",
    "                      'end_symbol': '<END>'})\n",
    "print(prepro_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff3367af",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = prepro_configs['char2idx']\n",
    "end_index = prepro_configs['end_symbol']\n",
    "vocab_size = prepro_configs['vocab_size']\n",
    "BATCH_SIZE = 2 \n",
    "MAX_SEQUENCE = 25\n",
    "EPOCHS = 30\n",
    "VALID_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32e5d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kargs = {'model_name': model_name,\n",
    "         'num_layers': 2,\n",
    "         'd_model': 512, # 단어의 차원 = 임베딩 dimension\n",
    "         'num_heads':8,\n",
    "         'dff': 2048, # 출력층의 노드 수\n",
    "         'input_vocab_size': vocab_size, # 단어 사전의 수\n",
    "         'target_vocab_size': vocab_size, # 단어 사전의 수\n",
    "         'maximum_position_encoding': MAX_SEQUENCE, # 포지션 인코더의 최대 시퀀스 길이\n",
    "         'end_token_idx': char2idx[end_index], # 종료 표지의 인덱스\n",
    "         'rate' : 0.1 # Dropout에 사용되는 비율\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5065474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순방향 마스크\n",
    "# seq의 값이 padding 0일 때만 1.0을 출력하고, 그 외에는 0을 출력하는 함수\n",
    "# 마스킹 대상을 1.0으로 만든다. 이후 -1e9라는 작은 수를 곱하고\n",
    "# 후에 softmax() 함수를 거쳐 값을 역전\n",
    "# 입력 2D -> return 4D\n",
    "def create_padding_mask(seq):\n",
    "    # seq 값이 0이면 1(true)를 출력하여  mask에 할당\n",
    "    mask = tf.cast(tf.math.equal(seq,0), tf.float32)\n",
    "    # 1D -> 3D로\n",
    "    return mask[:,tf.newaxis, tf.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27888e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삼각 행렬 만들기\n",
    "# 우삼각 부분만 1로 마스킹 영역을 표시\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1,0) # 하삼각행렬\n",
    "    # 하삼각행렬을 만든 후 1에서 빼서 역전시켜 상삼각 행렬을 만듦\n",
    "    return mask\n",
    "# create_padding_mask와 look_ahead_mask는 비슷한 모양\n",
    "# 자신의 뒤에 있는 단어나 패딩을 받는 부분은 보지 않기 위한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6912a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar): # (Encoder input, Decoder input)\n",
    "    # combined_mask 만드는 과정\n",
    "    enc_padding_mask = create_padding_mask(inp) # 인코더 패딩 마스크\n",
    "    dec_padding_mask = create_padding_mask(inp) # 디코더 두 번째 어텐션 블록에서 사용\n",
    "    \n",
    "    # 디코더의 첫 번째 어텐션 블록에서 사용되는 마스크\n",
    "    # 디코더가 받은 데이터를 패딩 처리 이후 순방향 마스킹을 하여 뒷 단어가 \n",
    "    # 참고되지 않도록 함\n",
    "    # combined_mask = look_ahead_mask 라는 이름으로 사용\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask,look_ahead_mask)\n",
    "                            # padding mask, subsequent mask\n",
    "    \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "    # 인코더 input 마스크(pad), 디코더 첫 번째 어텐션 마스크, 두 번째 어텐션 마스크(pad)\n",
    "                            # pad와 subse 중 해당되는 것으로 mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9ca6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_inputs : encoder_input_pad\n",
    "# index_ouputs : decoder_input_pad\n",
    "enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(index_inputs, index_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d3ea330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "def get_angles(pos,i, d_model):\n",
    "    # post: 각 문장의 단어 길이만큼의 공간, 단어의 위치 정보 \n",
    "    # i : 각 단어가 갖는 차원 만큼의 공간, 단어의 정보를 기록할 공간\n",
    "    # d_model : 단어 차원 수 (현재 512)\n",
    "    angle_rates = 1/np.power(10000,(2*i//2)/np.float32(d_model))\n",
    "    # 각 단어의 표현 공간에 위치 정보\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34af90fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:,np.newaxis],\n",
    "                           np.arange(d_model)[np.newaxis,:],\n",
    "                           d_model)\n",
    "    # 인덱스가 짝수인 경우 sin, 홀수인 경우 cos\n",
    "    angle_rads[:,0::2] = np.sin(angle_rads[:,0::2])\n",
    "    # 0번 부터 2개씩 건너뛰어 sin함수 적용\n",
    "    angle_rads[:,1::2] = np.cos(angle_rads[:,1::2])\n",
    "    # 1번 부터 2개씩 건너뛰어 cos함수 적용\n",
    "    pos_encoding = angle_rads[np.newaxis,...]\n",
    "    # ... : angle_rads의 차원을 그대로 가져옴\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50977299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q,k,v,mask):\n",
    "    matmul_qk = tf.matmul(q,k, transpose_b = True)# : attention score\n",
    "    # Q행렬과 전치된 K행렬을 내적 연산\n",
    "    # transpose_b : 두 번째 입력에 대해 전치 결정\n",
    "    # K 행렬의 차원 수 (열의 수)를 구한다.\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    # Key 벡터의 차원 수의 제곱근으로 나누어 크기를 줄임\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    \n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "    \n",
    "    # softmax 함수를 거쳐 매우작은 값은 0으로 마스킹 됨(우삼각)\n",
    "    # 자신보다 뒤에 나오는 단어는 참조하지 못함\n",
    "    # 그 외의 양의 값은 확률 정보가 됨(하삼각)\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis = -1)\n",
    "    # 패딩 마스크 순방향 마스크를 받을 부분은 -> 0\n",
    "    # 단어가 있는 자리는 양수 값을 기준\n",
    "    # 확률 값 Attention Score에 Value 벡터로 가중합을 수행\n",
    "    output = tf.matmul(attention_weights,v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7be8931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super().__init__() # 부모의 기능 가져오기, Layers 클래스의 메서드 가져오기\n",
    "        self.num_heads = kargs['num_heads'] # 어텐션 헤드 수 8\n",
    "        self.d_model = kargs['d_model'] # 단어의 차원 수 512\n",
    "        \n",
    "        # assert구문은 문제 발생 시 알림 역할\n",
    "        assert self.d_model % self.num_heads ==0\n",
    "        # d_model의 차원 수는 헤드의 개수로 나머지 없이 나뉘어야 함\n",
    "        \n",
    "        self.depth = self.d_model // self.num_heads\n",
    "        # 각 헤드에 입력될 벡터의 차원 수를 둘을 나눈 몫으로 결정\n",
    "        \n",
    "        # query, key, value 가중치 레이어 설정\n",
    "        # input 결과를 받을 수 있도록 차원 수를 동일하게\n",
    "        self.wq = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wk = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wv = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        \n",
    "        # 셀프 어텐션 결과를 출력하기 위한 레이어\n",
    "        self.dense = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        \n",
    "    # 각 배치 사이즈마다 데이터가 [seq_len X depth]로 되어 있는 것을\n",
    "    # [num_heads X seq_len X depth]로 변환, 헤드 수 만큼 분리하는 함수\n",
    "    # (depth == d_model == 임베딩 차원)\n",
    "    def split_heads(self, x, batch_size):\n",
    "        # (batch_size, seq_len, depth) -> (batch_size, seq_len, num_heads, depth)\n",
    "        # seq_len는 -1로 표기하여 자동 배정\n",
    "        # 숫자가 기입된 부분의 축을 변환하고 난 뒤 남은 축의 형태는 원래 텐서의\n",
    "        # 총 크기와 같도록 자동으로 결정\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, depth)로 치환\n",
    "        return tf.transpose(x, perm = [0,2,1,3])\n",
    "        \n",
    "    # fit단계(훈련)에서 실행되는 함수\n",
    "    def call(self, v,k,q,mask):\n",
    "        batch_size = tf.shape(q)[0] # batch size를 구함\n",
    "        \n",
    "        # (batch_size, seq_len, d_model)\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "        \n",
    "        # (batch_size, num_heads, seq_len, depth)\n",
    "        # num_heads 별로 depth(임베딩 차원)를 갖게함\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        \n",
    "        # 스케일 내적 어텐션 수행\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q,k,v,mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm = [0,2,1,3])\n",
    "        \n",
    "        # 4D -> 3D 변환 (batch_size, seq_len, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        # 가중합 (어텐션 결과)\n",
    "        \n",
    "        output = self.dense(concat_attention)\n",
    "        \n",
    "        # attention_weigth : softmax를 거친 확률 정보\n",
    "        # 어텐션을 얼마나 적용시킬 것인지에 대한 정보\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3ba022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position-wise Feed Forward Network\n",
    "def feed_forward_network(**kargs):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(kargs['dff'], activation ='relu'),\n",
    "        tf.keras.layers.Dense(kargs['d_model'])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e9982ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(**kargs)\n",
    "        self.ffn = feed_forward_network(**kargs)\n",
    "        \n",
    "        # 층 정규화(Layer Normalization)\n",
    "        # LayerNormalization은 같은 층별로 평균을 0, 표준편차 1로 정규화\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        # Dropout 레이어 생성\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        \n",
    "    def call(self,x, mask):\n",
    "        attn_output, _ = self.mha(x,x,x,mask)\n",
    "        # encoder_layer에서는 attention_weight를 받을 필요가 없음\n",
    "        attn_output = self.dropout1(attn_output) # Dropout 수행\n",
    "        out1 = self.layernorm1(x + attn_output) # Residual Connection & LayerNormalization\n",
    "        \n",
    "        ffn_output = self.ffn(out1) # out1에 대해 feed forward network\n",
    "        ffn_output = self.dropout2(ffn_output) # 드롭아웃 수행\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb6c7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LayerNormalization example\n",
    "# data = np.array([0.006,0.002,0.004,0.009,0.005,0.076,0.007,0.008,0.003])\n",
    "# data = data.reshape(-1,3)\n",
    "# print(data)\n",
    "# layer = tf.keras.layers.LayerNormalization(axis = 1)\n",
    "# output = layer(data)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d78925f",
   "metadata": {},
   "source": [
    "# 디코더 레이어와 인코더 레이어\n",
    "1. init()에서 인코더와 다르게 멀티 헤드 어텐션을 두 번 수행하기 위한 준비를 함\n",
    "2. call()은 인코더의 결과를 받는 enc_output과 순방향 마스크 어텐션을 위해 look\n",
    "    ahead_mask를 추가로 받음\n",
    "3. call()에서 첫 번째 어텐션은 순방향 마스크 어텐션을 수행 (두 번째 어텐션을 동일한\n",
    "    padding_mask)\n",
    "4. call()에서 두 번째 어텐션은 v,k에 enc_output을 넣지만 q는 첫 번째 어텐션 결과\n",
    "    를 넣는다.\n",
    "\n",
    "\n",
    "+ 디코더의 query(직전 단어)와 인코더의 key(현재 단어)를 내적 연산(Q,K_transposed)하고, 그 결과에 대해 인코더의 value를 가중합 함\n",
    "    + 뒷 단어가 무엇이 올지 알 수 없는 디코더의 입장에서는 context_vector로서 다음 단어를 예측할 수 있는 이코더의 정보를 활용 가능\n",
    "    + 두 번째 어텐션에서는 뒤쪽을 보지 않는 순방향 마스크를 사용하면 안됨\n",
    "    + 인코더처럼 패딩 마스크만 사용해야 함\n",
    "+ 직전 단어의 내용을 참조하여 이번에 나올 단어가 무엇인지를 알게 해주는 것\n",
    "Q : 찾고자 하는 단어 : 직전 단어\n",
    "K : 사전에 등록된 단어 : 기학습된 내용을 참조하여 어떤 단어에 집중해야 (유사한지) \n",
    "알려주는 기능\n",
    "V : 단어의 의미 : 현재 단어의 K의 내용을 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f7135ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(**kargs)\n",
    "        self.mha2 = MultiHeadAttention(**kargs)\n",
    "        self.ffn = feed_forward_network(**kargs)\n",
    "        \n",
    "        # 층 정규화\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        # Dropout 레이어 생성\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout3 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        \n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x,x,x,look_ahead_mask)\n",
    "        # look_ahead_mask : pad + subsequent, attn_weight_block1 : 확률로 된 어텐션 스코어\n",
    "        # attn1 : 가중합, attention을 적용한 벡터\n",
    "        attn1 = self.dropout1(attn1)\n",
    "        out1 = self.layernorm1(attn1 + x) # 잔차 연결 및 층 정규화 수행\n",
    "        \n",
    "        # 멀티 헤드 어텐션 레이어 2 수행\n",
    "                                                # k            v        q\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "        \n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        out3 = self.layernorm3(ffn_output +out2)\n",
    "        \n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1dad2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 모듈\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    '''\n",
    "        - 현재 단어의 임베딩 차원은 512, 사용할 인코더 레이어의 개수 2개\n",
    "        - 워드 임베딩은 케라스 이용, Flatten하지 않아 input_length 불필요\n",
    "        - 인코더 레이어 전체 연산 여러 번 반복\n",
    "        - 드롭아웃 레이어는 옵션\n",
    "    '''\n",
    "    def __init__(self, **kargs):\n",
    "        super().__init__()\n",
    "        self.d_model = kargs['d_model'] # 단어 임베딩 차원\n",
    "        self.num_layers = kargs['num_layers'] # 사용할 인코더 레이어 개수\n",
    "        \n",
    "        # 워드 임베딩 레이어 생성\n",
    "        # input_dim, output_dim, input_length / input_length는 Flatten이 없으면 생략 가능\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim = kargs['input_vocab_size'], output_dim = self.d_model)\n",
    "        \n",
    "        # 포지셔널 인코딩 레이어 생성\n",
    "        self.pos_encoding = positional_encoding(position = kargs['maximum_position_encoding'], d_model = self.d_model)\n",
    "        \n",
    "        # 인코더 레이어 생성 num_layers 수만큼 리스트 배열로 만든다\n",
    "        self.enc_layers = [EncoderLayer(**kargs) for _ in range(self.num_layers)]\n",
    "        \n",
    "        # 드롭아웃 레이어 생성\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "    \n",
    "    def call(self, x, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        # 가중치 곱하기(옵션) 각 워드 임베딩에 대해 스케일을 맞추는 과정\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:,:seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 인코더 레이어 연산을 반복하는 부분\n",
    "        # __init__()함수에서 생성된 복수의 인코더 레이어에 대하여 실제 수행\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0ddad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 모듈\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    '''\n",
    "        두 번의 어텐션에서 나온 가중치를 block1과 block2로 받아 \n",
    "        attention_weights에 묶어 출력한다.\n",
    "        그러나 사용하지는 않음\n",
    "    '''\n",
    "    def __init__(self, **kargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = kargs['d_model']\n",
    "        self.num_layers = kargs['num_layers']\n",
    "        \n",
    "        # 워드 임베딩 레이어 생성\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim= kargs['target_vocab_size'], output_dim = self.d_model)\n",
    "        \n",
    "        # 포지셔널 인코딩 레이어 생성\n",
    "        self.pos_encoding = positional_encoding(position= kargs['maximum_position_encoding'], d_model = self.d_model)\n",
    "        \n",
    "        # 디코더 레이어 생성, num_layers 수만큼 리스트 배열로 만듦\n",
    "        self.dec_layers = [DecoderLayer(**kargs) for _ in range(self.num_layers)]\n",
    "        \n",
    "        # 드롭 아웃 레이어 생성\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        \n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:,:seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            # block1, block2 : attention score\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "            \n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3865440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머 구현\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, **kargs):\n",
    "        super().__init__(name = kargs['model_name'])\n",
    "        self.end_token_idx = kargs['end_token_idx']\n",
    "        \n",
    "        self.encoder = Encoder(**kargs)\n",
    "        self.decoder = Decoder(**kargs)\n",
    "        \n",
    "        self.final_layer = tf.keras.layers.Dense(kargs['target_vocab_size'])\n",
    "    \n",
    "    def call(self, x):\n",
    "        inp, tar = x\n",
    "        \n",
    "        # 인코더 패딩 마스크, 디코더 순방향 마스크, 디코더 패딩 마스크 생성\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "        \n",
    "        # 인코더 결과 출력 (batch_size, inp_seq_len, d_model)\n",
    "        enc_output = self.encoder(inp, enc_padding_mask)\n",
    "        \n",
    "        # 디코더 결과 출력\n",
    "        dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "        \n",
    "        # batch_size, tar_seq_len, target_vocab_size\n",
    "        final_output = self.final_layer(dec_output)\n",
    "        \n",
    "        return final_output\n",
    "    \n",
    "    def inference(self, x):\n",
    "        inp = x\n",
    "        tar = tf.expand_dims([STD_INDEX], axis = 0)\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "        \n",
    "        enc_output = self.encoder(inp, enc_padding_mask)\n",
    "        \n",
    "        predict_tokens = list()\n",
    "        for t in range(0, MAX_SEQUENCE):\n",
    "            dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "            final_output = self.final_layer(dec_output)\n",
    "            outputs = tf.argmax(final_output, axis = -1).numpy()\n",
    "            print('outputs:',outputs)\n",
    "            pred_token = outputs[0][-1]\n",
    "            \n",
    "            if pred_token == self.end_token_idx:\n",
    "                break\n",
    "            predict_tokens.append(pred_token)\n",
    "            tar = tf.expand_dims([STD_INDEX]+ predict_tokens, axis=0)\n",
    "            _, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "        return predict_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e6e4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_logits : True  softmax함수를 거친 값이 아닌 일반 값이 필요함\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bc74d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 정의\n",
    "# <PAD> 0은 손실값 계산에서 제외해야 하는데 일반 손실함수는 이를 예외로 두지 않아\n",
    "# 새로 구현\n",
    "def loss(real, pred):\n",
    "    # 들어온 값이 0이면 True, 이를 False(0)로 변환하여 이후 계산에서 제외\n",
    "    mask = tf.math.logical_not(tf.math.equal(real,0))\n",
    "    \n",
    "    loss_ = loss_object(real,pred)\n",
    "    mask = tf.cast(mask, dtype = loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    # reduce_mean : 차원을 감소시킴, 차원과 관계없이 요소들의 평균값을 계산\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7eae6fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 함수 정의\n",
    "def accuracy(real,pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real,0))\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype = pred.dtype), axis = -1)\n",
    "    pred *= mask\n",
    "    acc = train_accuracy(real, pred)\n",
    "    \n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "785ddef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(**kargs)\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(1e-4), loss = loss, metrics = [accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60c6129b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists\n"
     ]
    }
   ],
   "source": [
    "# EarlyStopping\n",
    "earlystop_callback = EarlyStopping(monitor= 'val_accuracy', min_delta = 0.0001, patience = 10)\n",
    "\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights_cp'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print('already exists')\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok= True)\n",
    "    print('create complete')\n",
    "    \n",
    "checkpointer = ModelCheckpoint(checkpoint_path, monitor= 'val_accuracy', verbose = 1, save_best_only= True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d63f6da4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 2.0262 - accuracy: 0.4380\n",
      "Epoch 1: val_accuracy improved from -inf to 0.45395, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 14s 241ms/step - loss: 1.9973 - accuracy: 0.4424 - val_loss: 3.9542 - val_accuracy: 0.4539\n",
      "Epoch 2/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.3463 - accuracy: 0.4678\n",
      "Epoch 2: val_accuracy improved from 0.45395 to 0.48026, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 1.3463 - accuracy: 0.4678 - val_loss: 3.8836 - val_accuracy: 0.4803\n",
      "Epoch 3/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.9578 - accuracy: 0.4955\n",
      "Epoch 3: val_accuracy improved from 0.48026 to 0.50219, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.9578 - accuracy: 0.4955 - val_loss: 3.7837 - val_accuracy: 0.5022\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6745 - accuracy: 0.5255\n",
      "Epoch 4: val_accuracy improved from 0.50219 to 0.53783, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 125ms/step - loss: 0.6745 - accuracy: 0.5255 - val_loss: 3.5608 - val_accuracy: 0.5378\n",
      "Epoch 5/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3901 - accuracy: 0.5716\n",
      "Epoch 5: val_accuracy improved from 0.53783 to 0.58684, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 0.3901 - accuracy: 0.5716 - val_loss: 3.7990 - val_accuracy: 0.5868\n",
      "Epoch 6/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2712 - accuracy: 0.6156\n",
      "Epoch 6: val_accuracy improved from 0.58684 to 0.62610, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 0.2712 - accuracy: 0.6156 - val_loss: 4.1939 - val_accuracy: 0.6261\n",
      "Epoch 7/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.6462\n",
      "Epoch 7: val_accuracy improved from 0.62610 to 0.65695, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 0.2176 - accuracy: 0.6462 - val_loss: 3.6809 - val_accuracy: 0.6570\n",
      "Epoch 8/30\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.2426 - accuracy: 0.6692\n",
      "Epoch 8: val_accuracy improved from 0.65695 to 0.67599, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 0.2303 - accuracy: 0.6704 - val_loss: 4.2161 - val_accuracy: 0.6760\n",
      "Epoch 9/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1167 - accuracy: 0.6929\n",
      "Epoch 9: val_accuracy improved from 0.67599 to 0.70029, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 128ms/step - loss: 0.1167 - accuracy: 0.6929 - val_loss: 3.6416 - val_accuracy: 0.7003\n",
      "Epoch 10/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.7143\n",
      "Epoch 10: val_accuracy improved from 0.70029 to 0.72039, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 128ms/step - loss: 0.0848 - accuracy: 0.7143 - val_loss: 5.1110 - val_accuracy: 0.7204\n",
      "Epoch 11/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.7323\n",
      "Epoch 11: val_accuracy improved from 0.72039 to 0.73744, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 134ms/step - loss: 0.0626 - accuracy: 0.7323 - val_loss: 4.1823 - val_accuracy: 0.7374\n",
      "Epoch 12/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.7490\n",
      "Epoch 12: val_accuracy improved from 0.73744 to 0.75329, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 0.0327 - accuracy: 0.7490 - val_loss: 4.3226 - val_accuracy: 0.7533\n",
      "Epoch 13/30\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.0186 - accuracy: 0.7626\n",
      "Epoch 13: val_accuracy improved from 0.75329 to 0.76721, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 126ms/step - loss: 0.0180 - accuracy: 0.7634 - val_loss: 4.5986 - val_accuracy: 0.7672\n",
      "Epoch 14/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.7761\n",
      "Epoch 14: val_accuracy improved from 0.76721 to 0.77914, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0140 - accuracy: 0.7761 - val_loss: 4.2376 - val_accuracy: 0.7791\n",
      "Epoch 15/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.7870\n",
      "Epoch 15: val_accuracy improved from 0.77914 to 0.78947, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 122ms/step - loss: 0.0108 - accuracy: 0.7870 - val_loss: 4.2915 - val_accuracy: 0.7895\n",
      "Epoch 16/30\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.0126 - accuracy: 0.7954\n",
      "Epoch 16: val_accuracy improved from 0.78947 to 0.79811, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 129ms/step - loss: 0.0122 - accuracy: 0.7961 - val_loss: 4.4565 - val_accuracy: 0.7981\n",
      "Epoch 17/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.8044\n",
      "Epoch 17: val_accuracy improved from 0.79811 to 0.80611, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 121ms/step - loss: 0.0074 - accuracy: 0.8044 - val_loss: 4.5529 - val_accuracy: 0.8061\n",
      "Epoch 18/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.8118\n",
      "Epoch 18: val_accuracy improved from 0.80611 to 0.81323, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0056 - accuracy: 0.8118 - val_loss: 4.4118 - val_accuracy: 0.8132\n",
      "Epoch 19/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.8184\n",
      "Epoch 19: val_accuracy improved from 0.81323 to 0.81960, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 128ms/step - loss: 0.0057 - accuracy: 0.8184 - val_loss: 4.3300 - val_accuracy: 0.8196\n",
      "Epoch 20/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.8244\n",
      "Epoch 20: val_accuracy improved from 0.81960 to 0.82533, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 121ms/step - loss: 0.0038 - accuracy: 0.8244 - val_loss: 4.3800 - val_accuracy: 0.8253\n",
      "Epoch 21/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.8297\n",
      "Epoch 21: val_accuracy improved from 0.82533 to 0.83051, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 125ms/step - loss: 0.0030 - accuracy: 0.8297 - val_loss: 4.4516 - val_accuracy: 0.8305\n",
      "Epoch 22/30\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.0031 - accuracy: 0.8342\n",
      "Epoch 22: val_accuracy improved from 0.83051 to 0.83523, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 130ms/step - loss: 0.0030 - accuracy: 0.8346 - val_loss: 4.3901 - val_accuracy: 0.8352\n",
      "Epoch 23/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.8390\n",
      "Epoch 23: val_accuracy improved from 0.83523 to 0.83953, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 0.0029 - accuracy: 0.8390 - val_loss: 4.3526 - val_accuracy: 0.8395\n",
      "Epoch 24/30\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.0030 - accuracy: 0.8428\n",
      "Epoch 24: val_accuracy improved from 0.83953 to 0.84348, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 130ms/step - loss: 0.0033 - accuracy: 0.8431 - val_loss: 4.3462 - val_accuracy: 0.8435\n",
      "Epoch 25/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.8468\n",
      "Epoch 25: val_accuracy improved from 0.84348 to 0.84711, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 119ms/step - loss: 0.0025 - accuracy: 0.8468 - val_loss: 4.4169 - val_accuracy: 0.8471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.8502\n",
      "Epoch 26: val_accuracy improved from 0.84711 to 0.85046, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0037 - accuracy: 0.8502 - val_loss: 4.4878 - val_accuracy: 0.8505\n",
      "Epoch 27/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.8534\n",
      "Epoch 27: val_accuracy improved from 0.85046 to 0.85356, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 0.0020 - accuracy: 0.8534 - val_loss: 4.5222 - val_accuracy: 0.8536\n",
      "Epoch 28/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.8563\n",
      "Epoch 28: val_accuracy improved from 0.85356 to 0.85644, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 121ms/step - loss: 0.0028 - accuracy: 0.8563 - val_loss: 4.4935 - val_accuracy: 0.8564\n",
      "Epoch 29/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.8590\n",
      "Epoch 29: val_accuracy improved from 0.85644 to 0.85912, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 122ms/step - loss: 0.0020 - accuracy: 0.8590 - val_loss: 4.4566 - val_accuracy: 0.8591\n",
      "Epoch 30/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.8616\n",
      "Epoch 30: val_accuracy improved from 0.85912 to 0.86162, saving model to C:/pytest/data/transformer\\weights_cp\n",
      "9/9 [==============================] - 1s 122ms/step - loss: 0.0022 - accuracy: 0.8616 - val_loss: 4.4662 - val_accuracy: 0.8616\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([index_inputs, index_outputs], index_targets,\n",
    "                   batch_size= BATCH_SIZE, epochs= EPOCHS,\n",
    "                   validation_split=VALID_SPLIT, callbacks= [earlystop_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4cd6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.xlabel('EPOCHS')\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string,'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c4ede42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
