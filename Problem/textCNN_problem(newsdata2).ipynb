{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deabec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"C:/pytest/\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13754d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a63dc7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('뉴스데이터_train.csv', encoding = 'cp949')\n",
    "test = pd.read_csv('뉴스데이터_test.csv', encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b15dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_train = train.loc[:,['id', '날짜','분류1','텍스트']]\n",
    "data1_test = test.loc[:,['id','날짜','분류1','텍스트']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9db35dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_train_classes = data1_train['분류1']\n",
    "data1_test_classes = data1_test['분류1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041de3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_train_class = []\n",
    "data1_test_class = []\n",
    "for word in data1_train_classes:\n",
    "    data1_train_class.append(word.split(',')[0])\n",
    "for word in data1_test_classes:\n",
    "    data1_test_class.append(word.split(',')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6be1d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_train['분류1_상위'] = pd.Series(data1_train_class)\n",
    "data1_test['분류1_상위'] = pd.Series(data1_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b20c2097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1\n",
    "data1_train_X = data1_train['텍스트']\n",
    "data1_train_y = data1_train['분류1_상위']\n",
    "data1_test_X = data1_test['텍스트']\n",
    "data1_test_y = data1_test['분류1_상위']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cb3a67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath:  C:\\Anaconda3\\lib\\site-packages\n",
      "classpath:  C:\\Anaconda3\\lib\\site-packages\\rhinoMorph/lib/rhino.jar\n",
      "RHINO started!\n"
     ]
    }
   ],
   "source": [
    "import rhinoMorph\n",
    "rn = rhinoMorph.startRhino()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c812a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d595aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_morphed(rn, data_text):\n",
    "    morphed_text = []\n",
    "    for word in tqdm(data_text):\n",
    "        morphed_text_lst = rhinoMorph.onlyMorph_list(rn, word, pos = ['NNP','NNG','VV','VA','XR','IC','MM','MAG','MAJ'], eomi = True)\n",
    "        joined_text = ' '.join(morphed_text_lst)\n",
    "        morphed_text.append(joined_text)\n",
    "        morphed_text_series = pd.Series(morphed_text)\n",
    "    return morphed_text_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e99f3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6792/6792 [00:11<00:00, 588.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# data1\n",
    "data1_train_X_morphed = auto_morphed(rn, data1_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e826734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소길이 : 4\n",
      "최대 길이 : 54\n",
      "평균 길이 : 19.5\n",
      "중위수 길이 : 19.0\n",
      "구간별 최대 길이 : [ 4. 16. 19. 22. 35. 54.]\n"
     ]
    }
   ],
   "source": [
    "text_len = [len(line.split()) for line in data1_train_X_morphed]\n",
    "print('최소길이 : {}\\n최대 길이 : {}\\n평균 길이 : {}\\n중위수 길이 : {}\\n구간별 최대 길이 : {}'.format(np.min(text_len), np.max(text_len), np.round(np.mean(text_len), 1), np.median(text_len), np.percentile(text_len, [0,25,50,75,99,100])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da56a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "maxlen = 30\n",
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb87ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(data1_train_X_morphed)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6372af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d42b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequencing \n",
    "data1_train_X_sequencing = tokenizer.texts_to_sequences(data1_train_X_morphed)\n",
    "# padding\n",
    "data1_train_X_padding = pad_sequences(data1_train_X_sequencing, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d493c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "e = LabelEncoder()\n",
    "e.fit(data1_train_y)\n",
    "data1_train_y_labeling = e.transform(data1_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db4cf4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IT_과학' '경제' '국제' '문화' '미분류' '사회' '스포츠' '정치' '지역']\n"
     ]
    }
   ],
   "source": [
    "print(e.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69d4e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(sequences, dimension):\n",
    "  results = np.zeros((len(sequences), dimension))\n",
    "  for i, sequence in enumerate(sequences):\n",
    "    results[i, sequence] = 1\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a26d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_train_y_1hot = to_one_hot(data1_train_y_labeling, len(e.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff22dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_number = len(e.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c45e933",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 30, 200)           2000000   \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 28, 100)           60100     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2800)              0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2800)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                89632     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,150,029\n",
      "Trainable params: 2,150,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers, regularizers\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim = max_words, output_dim = embedding_dim, input_length = maxlen))\n",
    "\n",
    "model.add(layers.Conv1D(100, kernel_size = 3,activation = 'relu'))\n",
    "# model.add(layers.MaxPooling1D(pool_size = 2)) # maxpooling + lstm : 82.8 / maxpooling+flatten : 84.1\n",
    "model.add(layers.Flatten())\n",
    "# model.add(layers.Dropout(0.4)) # conv + dropout + lstm + dropout : 84.5\n",
    "\n",
    "# model.add(layers.LSTM(100)) # 83.6\n",
    "\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(32, activation = 'relu'))\n",
    "model.add(layers.Dense(class_number, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cff25103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "149/149 [==============================] - 2s 11ms/step - loss: 1.4169 - acc: 0.4880 - val_loss: 1.1642 - val_acc: 0.5692\n",
      "Epoch 2/10\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.8484 - acc: 0.7158 - val_loss: 0.9738 - val_acc: 0.6703\n",
      "Epoch 3/10\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.4868 - acc: 0.8568 - val_loss: 0.9447 - val_acc: 0.6963\n",
      "Epoch 4/10\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.2357 - acc: 0.9354 - val_loss: 1.0609 - val_acc: 0.7041\n",
      "Epoch 5/10\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0978 - acc: 0.9790 - val_loss: 1.3746 - val_acc: 0.6801\n",
      "Epoch 6/10\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0400 - acc: 0.9916 - val_loss: 1.3571 - val_acc: 0.7144\n",
      "Epoch 7/10\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0168 - acc: 0.9958 - val_loss: 1.5566 - val_acc: 0.7105\n",
      "Epoch 8/10\n",
      "149/149 [==============================] - 1s 10ms/step - loss: 0.0065 - acc: 0.9987 - val_loss: 1.7234 - val_acc: 0.7134\n",
      "Epoch 9/10\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.0040 - acc: 0.9994 - val_loss: 2.0357 - val_acc: 0.7076\n",
      "Epoch 10/10\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 2.0857 - val_acc: 0.7130\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss= 'categorical_crossentropy',optimizer= 'rmsprop',metrics = ['acc'])\n",
    "with tf.device('/CPU:0'):\n",
    "    history1 = model.fit(data1_train_X_padding, data1_train_y_1hot,epochs = 10, batch_size =32, validation_split= 0.3,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81678bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2265/2265 [00:02<00:00, 781.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# data1 test\n",
    "data1_test_X_morphed = auto_morphed(rn, data1_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47e158ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1\n",
    "# sequencing\n",
    "data1_test_X_sequencing = tokenizer.texts_to_sequences(data1_test_X_morphed)\n",
    "# padding\n",
    "data1_test_X_padding = pad_sequences(data1_test_X_sequencing, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a05c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 test_y\n",
    "data1_test_y_labeling= e.transform(data1_test_y)\n",
    "data1_test_y_1hot = to_one_hot(data1_test_y_labeling, class_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cd37cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 3ms/step - loss: 2.0408 - acc: 0.7236\n"
     ]
    }
   ],
   "source": [
    "# data1 분류1\n",
    "with tf.device('/CPU:0'):\n",
    "    eval1 = model.evaluate(data1_test_X_padding, data1_test_y_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117f18af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
